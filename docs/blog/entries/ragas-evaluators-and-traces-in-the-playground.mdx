---
title: "RAGAS Evaluators and Traces in the Playground"
slug: ragas-evaluators-and-traces-in-the-playground
date: 2024-08-12
tags: [v0.22.0]
---


import Image from "@theme/IdealImage";




We're excited to announce two major features this week:

1. We've integrated [RAGAS evaluators](https://docs.ragas.io/) into agenta. Two new evaluators have been added: **RAG Faithfulness** (measuring how consistent the LLM output is with the context) and **Context Relevancy** (assessing how relevant the retrieved context is to the question). Both evaluators use intermediate outputs within the trace to calculate the final score.

   [Check out the tutorial](/evaluation/evaluators/rag-evaluators) to learn how to use RAG evaluators.

{" "}

<div>
  <Image
    img={require("/images/changelog/rag_faithfulness.png")}
    alt="Button for exporting evaluation results"
    style={{
      display: "block",
      margin: "20px auto",
      textAlign: "center",
    }}
  />
</div>

2. You can now **view traces directly in the playground**. This feature enables you to debug your application while configuring itâ€”for example, by examining the prompts sent to the LLM or reviewing intermediate outputs.

   <div>
     <Image
       img={require("/images/changelog/trace_in_playground.png")}
       alt="Button for exporting evaluation results"
    style={{
      display: "block",
      margin: "20px auto",
      textAlign: "center",
    }}
     />
   </div>

:::note
Both features are available exclusively in the cloud and enterprise versions of agenta.
:::

---
