---
title: "Quick Start"
sidebar_label: "Quick Start"
description: "Quick start guide for running evaluations programmatically with the Agenta SDK"
sidebar_position: 1
---

This quick start guide will help you run your first evaluation using the Agenta Python SDK.

## Prerequisites

- Python 3.8 or higher
- Agenta account with API key
- An LLM application deployed in Agenta

## Installation

```bash
pip install -U agenta
```

## What you'll learn

- How to initialize the SDK
- How to create test sets programmatically
- How to configure and run evaluations
- How to retrieve evaluation results

## Quick example

```python
import asyncio
import agenta as ag
from agenta.sdk.evaluations import aevaluate

ag.init(host="https://cloud.agenta.ai", api_key="your-api-key")

@ag.application(
    slug="capital_finder",
    name="Capital Finder",
)
async def capital_finder(country: str):
    capitals = {
        "Germany": "Berlin",
        "France": "Paris",
    }
    return capitals.get(country, "Unknown")

@ag.evaluator(
    slug="exact_match",
    name="Exact Match",
)
async def exact_match(expected: str, outputs: str):
    return {
        "score": 1.0 if outputs == expected else 0.0,
        "success": outputs == expected,
    }

async def run():
    testset = await ag.testsets.acreate(
        name="my_test_set",
        data=[
            {"country": "Germany", "expected": "Berlin"},
            {"country": "France", "expected": "Paris"},
        ],
    )

    result = await aevaluate(
        testsets=[testset.id],
        applications=[capital_finder],
        evaluators=[exact_match],
    )
    return result

result = asyncio.run(run())
print(result)
```

## Next steps

- Learn about [setup and configuration](/evaluation/evaluation-from-sdk/setup-configuration)
- Explore [managing test sets with the SDK](/evaluation/evaluation-from-sdk/managing-test-sets)
- Understand [configuring evaluators](/evaluation/evaluation-from-sdk/configuring-evaluators)
- See how to [run evaluations](/evaluation/evaluation-from-sdk/running-evaluations) in detail
