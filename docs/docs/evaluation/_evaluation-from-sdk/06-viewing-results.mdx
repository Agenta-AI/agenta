---
title: "Viewing Results"
sidebar_label: "Viewing Results"
description: "Learn how to retrieve and analyze evaluation results using the SDK"
sidebar_position: 6
---

## Fetching overall results

`aevaluate()` returns the run, scenarios, and metrics in a single object. You can inspect the metrics directly:

```python
metrics = result["metrics"]
print(metrics)
```

## Fetching detailed results

Use the built-in display helper to render a detailed report:

```python
import asyncio
from agenta.sdk.evaluations import display

async def main():
    await display(result)

asyncio.run(main())
```

## Next steps

- Learn about [human evaluation](/evaluation/human-evaluation/quick-start)
- Explore [comparing evaluations in the UI](/evaluation/evaluation-from-ui/comparing-runs)
- See all [evaluator types](/evaluation/configure-evaluators/overview)
