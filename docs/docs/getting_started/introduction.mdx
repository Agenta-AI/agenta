---
slug: /
title: What is Agenta?
description: "The open-source end-to-end LLMOps platform."
id: introduction
sidebar_position: 0
---

import Image from "@theme/IdealImage";

<Image img={require("/images/agenta_mockup_whitebg.png")} className="dark:hidden" />
<img className="hidden dark:block" src="/images/agenta_mockup_blackbg.png" />
Agenta is an open-source platform that helps **developers** and **product teams** build robust AI applications powered by LLMs. It offers all the tools for **prompt management and evaluation**.

### With Agenta, you can:

1. Rapidly [**experiment** and **compare** prompts](/prompt_management/prompt_engineering) on [any LLM workflow](/prompt_management/setting_up/custom_applications) (chain-of-prompts, Retrieval Augmented Generation (RAG), LLM agents...)
2. Rapidly [**create test sets**](/evaluation/test_sets) and **golden datasets** for evaluation
3. **Evaluate** your application with pre-existing or **custom evaluators**
4. **Annotate** and **A/B test** your applications with **human feedback**
5. [**Collaborate with product teams**](/misc/team_management) for prompt engineering and evaluation
6. [**Deploy your application**](/prompt_management/deployment) in one-click in the UI, through CLI, or through github workflows.

Agenta focuses on increasing the speed of the development cycle of LLM applications by increasing the speed of experimentation.

## How is Agenta different?

### Works with any LLM app workflow

Agenta enables prompt engineering and evaluation on any LLM app architecture, such as **Chain of Prompts**, **RAG**, or **LLM agents**. It is compatible with any framework like **Langchain** or **LlamaIndex**, and works with any model provider, such as **OpenAI**, **Cohere**, or **local models**.

[Jump here](/prompt_management/setting_up/custom_applications) to see how to use your own custom application with Agenta and [here](/guides/how_does_agenta_work) to understand more how Agenta works.

### Enable collaboration between developers and product teams

Agenta empowers **non-developers** to iterate on the configuration of any custom LLM application, evaluate it, annotate it, A/B test it, and deploy it, all within the user interface.

By **adding a few lines to your application code**, you can create a prompt playground that allows non-developers to experiment with prompts for your application and use all the tools within Agenta.
