# This file was auto-generated by Fern from our API Definition.

import typing

from ..core.client_wrapper import AsyncClientWrapper, SyncClientWrapper
from ..core.request_options import RequestOptions
from ..types.evaluation_status_enum import EvaluationStatusEnum
from ..types.evaluation_type import EvaluationType
from ..types.human_evaluation import HumanEvaluation
from ..types.human_evaluation_scenario import HumanEvaluationScenario
from ..types.human_evaluation_scenario_input import HumanEvaluationScenarioInput
from ..types.human_evaluation_scenario_output import HumanEvaluationScenarioOutput
from ..types.score import Score
from ..types.simple_evaluation_output import SimpleEvaluationOutput
from .raw_client import AsyncRawHumanEvaluationsClient, RawHumanEvaluationsClient

# this is used as the default value for optional parameters
OMIT = typing.cast(typing.Any, ...)


class HumanEvaluationsClient:
    def __init__(self, *, client_wrapper: SyncClientWrapper):
        self._raw_client = RawHumanEvaluationsClient(client_wrapper=client_wrapper)

    @property
    def with_raw_response(self) -> RawHumanEvaluationsClient:
        """
        Retrieves a raw implementation of this client that returns raw responses.

        Returns
        -------
        RawHumanEvaluationsClient
        """
        return self._raw_client

    def fetch_list_human_evaluations(
        self, *, app_id: str, request_options: typing.Optional[RequestOptions] = None
    ) -> typing.List[HumanEvaluation]:
        """
        Fetches a list of evaluations, optionally filtered by an app ID.

        Args:
            app_id (Optional[str]): An optional app ID to filter the evaluations.

        Returns:
            List[HumanEvaluation]: A list of evaluations.

        Parameters
        ----------
        app_id : str

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        typing.List[HumanEvaluation]
            Successful Response

        Examples
        --------
        from agenta import AgentaApi

        client = AgentaApi(
            api_key="YOUR_API_KEY",
        )
        client.human_evaluations.fetch_list_human_evaluations(
            app_id="app_id",
        )
        """
        _response = self._raw_client.fetch_list_human_evaluations(
            app_id=app_id, request_options=request_options
        )
        return _response.data

    def create_human_evaluation(
        self,
        *,
        app_id: str,
        variant_ids: typing.Sequence[str],
        evaluation_type: EvaluationType,
        inputs: typing.Sequence[str],
        testset_id: str,
        status: str,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> SimpleEvaluationOutput:
        """
        Creates a new comparison table document
        Raises:
            HTTPException: _description_
        Returns:
            _description_

        Parameters
        ----------
        app_id : str

        variant_ids : typing.Sequence[str]

        evaluation_type : EvaluationType

        inputs : typing.Sequence[str]

        testset_id : str

        status : str

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        SimpleEvaluationOutput
            Successful Response

        Examples
        --------
        from agenta import AgentaApi

        client = AgentaApi(
            api_key="YOUR_API_KEY",
        )
        client.human_evaluations.create_human_evaluation(
            app_id="app_id",
            variant_ids=["variant_ids"],
            evaluation_type="human_a_b_testing",
            inputs=["inputs"],
            testset_id="testset_id",
            status="status",
        )
        """
        _response = self._raw_client.create_human_evaluation(
            app_id=app_id,
            variant_ids=variant_ids,
            evaluation_type=evaluation_type,
            inputs=inputs,
            testset_id=testset_id,
            status=status,
            request_options=request_options,
        )
        return _response.data

    def delete_evaluations(
        self,
        *,
        evaluations_ids: typing.Sequence[str],
        request_options: typing.Optional[RequestOptions] = None,
    ) -> typing.List[str]:
        """
        Delete specific comparison tables based on their unique IDs.

        Args:
            payload (List[str]): The unique identifiers of the comparison tables to delete.

        Returns:
        A list of the deleted comparison tables' IDs.

        Parameters
        ----------
        evaluations_ids : typing.Sequence[str]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        typing.List[str]
            Successful Response

        Examples
        --------
        from agenta import AgentaApi

        client = AgentaApi(
            api_key="YOUR_API_KEY",
        )
        client.human_evaluations.delete_evaluations(
            evaluations_ids=["evaluations_ids"],
        )
        """
        _response = self._raw_client.delete_evaluations(
            evaluations_ids=evaluations_ids, request_options=request_options
        )
        return _response.data

    def fetch_human_evaluation(
        self,
        evaluation_id: str,
        *,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> HumanEvaluation:
        """
        Fetches a single evaluation based on its ID.

        Args:
            evaluation_id (str): The ID of the evaluation to fetch.

        Returns:
            HumanEvaluation: The fetched evaluation.

        Parameters
        ----------
        evaluation_id : str

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        HumanEvaluation
            Successful Response

        Examples
        --------
        from agenta import AgentaApi

        client = AgentaApi(
            api_key="YOUR_API_KEY",
        )
        client.human_evaluations.fetch_human_evaluation(
            evaluation_id="evaluation_id",
        )
        """
        _response = self._raw_client.fetch_human_evaluation(
            evaluation_id, request_options=request_options
        )
        return _response.data

    def update_human_evaluation(
        self,
        evaluation_id: str,
        *,
        status: typing.Optional[EvaluationStatusEnum] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> typing.Optional[typing.Any]:
        """
        Updates an evaluation's status.

        Raises:
            HTTPException: If the columns in the test set do not match with the inputs in the variant.

        Returns:
            None: A 204 No Content status code, indicating that the update was successful.

        Parameters
        ----------
        evaluation_id : str

        status : typing.Optional[EvaluationStatusEnum]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        typing.Optional[typing.Any]
            Successful Response

        Examples
        --------
        from agenta import AgentaApi

        client = AgentaApi(
            api_key="YOUR_API_KEY",
        )
        client.human_evaluations.update_human_evaluation(
            evaluation_id="evaluation_id",
        )
        """
        _response = self._raw_client.update_human_evaluation(
            evaluation_id, status=status, request_options=request_options
        )
        return _response.data

    def fetch_human_evaluation_scenarios(
        self,
        evaluation_id: str,
        *,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> typing.List[HumanEvaluationScenario]:
        """
        Fetches evaluation scenarios for a given evaluation ID.

        Arguments:
            evaluation_id (str): The ID of the evaluation for which to fetch scenarios.

        Raises:
            HTTPException: If the evaluation is not found or access is denied.

        Returns:
            List[EvaluationScenario]: A list of evaluation scenarios.

        Parameters
        ----------
        evaluation_id : str

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        typing.List[HumanEvaluationScenario]
            Successful Response

        Examples
        --------
        from agenta import AgentaApi

        client = AgentaApi(
            api_key="YOUR_API_KEY",
        )
        client.human_evaluations.fetch_human_evaluation_scenarios(
            evaluation_id="evaluation_id",
        )
        """
        _response = self._raw_client.fetch_human_evaluation_scenarios(
            evaluation_id, request_options=request_options
        )
        return _response.data

    def update_evaluation_scenario_router(
        self,
        evaluation_id: str,
        evaluation_scenario_id: str,
        evaluation_type: EvaluationType,
        *,
        vote: typing.Optional[str] = OMIT,
        score: typing.Optional[Score] = OMIT,
        correct_answer: typing.Optional[str] = OMIT,
        outputs: typing.Optional[typing.Sequence[HumanEvaluationScenarioOutput]] = OMIT,
        inputs: typing.Optional[typing.Sequence[HumanEvaluationScenarioInput]] = OMIT,
        is_pinned: typing.Optional[bool] = OMIT,
        note: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> typing.Optional[typing.Any]:
        """
        Updates an evaluation scenario's vote or score based on its type.

        Raises:
            HTTPException: If update fails or unauthorized.

        Returns:
            None: 204 No Content status code upon successful update.

        Parameters
        ----------
        evaluation_id : str

        evaluation_scenario_id : str

        evaluation_type : EvaluationType

        vote : typing.Optional[str]

        score : typing.Optional[Score]

        correct_answer : typing.Optional[str]

        outputs : typing.Optional[typing.Sequence[HumanEvaluationScenarioOutput]]

        inputs : typing.Optional[typing.Sequence[HumanEvaluationScenarioInput]]

        is_pinned : typing.Optional[bool]

        note : typing.Optional[str]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        typing.Optional[typing.Any]
            Successful Response

        Examples
        --------
        from agenta import AgentaApi

        client = AgentaApi(
            api_key="YOUR_API_KEY",
        )
        client.human_evaluations.update_evaluation_scenario_router(
            evaluation_id="evaluation_id",
            evaluation_scenario_id="evaluation_scenario_id",
            evaluation_type="human_a_b_testing",
        )
        """
        _response = self._raw_client.update_evaluation_scenario_router(
            evaluation_id,
            evaluation_scenario_id,
            evaluation_type,
            vote=vote,
            score=score,
            correct_answer=correct_answer,
            outputs=outputs,
            inputs=inputs,
            is_pinned=is_pinned,
            note=note,
            request_options=request_options,
        )
        return _response.data

    def get_evaluation_scenario_score_router(
        self,
        evaluation_scenario_id: str,
        *,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> typing.Dict[str, str]:
        """
        Fetch the score of a specific evaluation scenario.

        Args:
            evaluation_scenario_id: The ID of the evaluation scenario to fetch.

        Returns:
            Dictionary containing the scenario ID and its score.

        Parameters
        ----------
        evaluation_scenario_id : str

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        typing.Dict[str, str]
            Successful Response

        Examples
        --------
        from agenta import AgentaApi

        client = AgentaApi(
            api_key="YOUR_API_KEY",
        )
        client.human_evaluations.get_evaluation_scenario_score_router(
            evaluation_scenario_id="evaluation_scenario_id",
        )
        """
        _response = self._raw_client.get_evaluation_scenario_score_router(
            evaluation_scenario_id, request_options=request_options
        )
        return _response.data

    def update_evaluation_scenario_score_router(
        self,
        evaluation_scenario_id: str,
        *,
        score: float,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> typing.Optional[typing.Any]:
        """
        Updates the score of an evaluation scenario.

        Raises:
            HTTPException: Server error if the evaluation update fails.

        Returns:
            None: 204 No Content status code upon successful update.

        Parameters
        ----------
        evaluation_scenario_id : str

        score : float

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        typing.Optional[typing.Any]
            Successful Response

        Examples
        --------
        from agenta import AgentaApi

        client = AgentaApi(
            api_key="YOUR_API_KEY",
        )
        client.human_evaluations.update_evaluation_scenario_score_router(
            evaluation_scenario_id="evaluation_scenario_id",
            score=1.1,
        )
        """
        _response = self._raw_client.update_evaluation_scenario_score_router(
            evaluation_scenario_id, score=score, request_options=request_options
        )
        return _response.data

    def fetch_results(
        self,
        evaluation_id: str,
        *,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> typing.Optional[typing.Any]:
        """
        Fetch all the results for one the comparison table

        Arguments:
            evaluation_id -- _description_

        Returns:
            _description_

        Parameters
        ----------
        evaluation_id : str

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        typing.Optional[typing.Any]
            Successful Response

        Examples
        --------
        from agenta import AgentaApi

        client = AgentaApi(
            api_key="YOUR_API_KEY",
        )
        client.human_evaluations.fetch_results(
            evaluation_id="evaluation_id",
        )
        """
        _response = self._raw_client.fetch_results(
            evaluation_id, request_options=request_options
        )
        return _response.data


class AsyncHumanEvaluationsClient:
    def __init__(self, *, client_wrapper: AsyncClientWrapper):
        self._raw_client = AsyncRawHumanEvaluationsClient(client_wrapper=client_wrapper)

    @property
    def with_raw_response(self) -> AsyncRawHumanEvaluationsClient:
        """
        Retrieves a raw implementation of this client that returns raw responses.

        Returns
        -------
        AsyncRawHumanEvaluationsClient
        """
        return self._raw_client

    async def fetch_list_human_evaluations(
        self, *, app_id: str, request_options: typing.Optional[RequestOptions] = None
    ) -> typing.List[HumanEvaluation]:
        """
        Fetches a list of evaluations, optionally filtered by an app ID.

        Args:
            app_id (Optional[str]): An optional app ID to filter the evaluations.

        Returns:
            List[HumanEvaluation]: A list of evaluations.

        Parameters
        ----------
        app_id : str

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        typing.List[HumanEvaluation]
            Successful Response

        Examples
        --------
        import asyncio

        from agenta import AsyncAgentaApi

        client = AsyncAgentaApi(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.human_evaluations.fetch_list_human_evaluations(
                app_id="app_id",
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.fetch_list_human_evaluations(
            app_id=app_id, request_options=request_options
        )
        return _response.data

    async def create_human_evaluation(
        self,
        *,
        app_id: str,
        variant_ids: typing.Sequence[str],
        evaluation_type: EvaluationType,
        inputs: typing.Sequence[str],
        testset_id: str,
        status: str,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> SimpleEvaluationOutput:
        """
        Creates a new comparison table document
        Raises:
            HTTPException: _description_
        Returns:
            _description_

        Parameters
        ----------
        app_id : str

        variant_ids : typing.Sequence[str]

        evaluation_type : EvaluationType

        inputs : typing.Sequence[str]

        testset_id : str

        status : str

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        SimpleEvaluationOutput
            Successful Response

        Examples
        --------
        import asyncio

        from agenta import AsyncAgentaApi

        client = AsyncAgentaApi(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.human_evaluations.create_human_evaluation(
                app_id="app_id",
                variant_ids=["variant_ids"],
                evaluation_type="human_a_b_testing",
                inputs=["inputs"],
                testset_id="testset_id",
                status="status",
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.create_human_evaluation(
            app_id=app_id,
            variant_ids=variant_ids,
            evaluation_type=evaluation_type,
            inputs=inputs,
            testset_id=testset_id,
            status=status,
            request_options=request_options,
        )
        return _response.data

    async def delete_evaluations(
        self,
        *,
        evaluations_ids: typing.Sequence[str],
        request_options: typing.Optional[RequestOptions] = None,
    ) -> typing.List[str]:
        """
        Delete specific comparison tables based on their unique IDs.

        Args:
            payload (List[str]): The unique identifiers of the comparison tables to delete.

        Returns:
        A list of the deleted comparison tables' IDs.

        Parameters
        ----------
        evaluations_ids : typing.Sequence[str]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        typing.List[str]
            Successful Response

        Examples
        --------
        import asyncio

        from agenta import AsyncAgentaApi

        client = AsyncAgentaApi(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.human_evaluations.delete_evaluations(
                evaluations_ids=["evaluations_ids"],
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.delete_evaluations(
            evaluations_ids=evaluations_ids, request_options=request_options
        )
        return _response.data

    async def fetch_human_evaluation(
        self,
        evaluation_id: str,
        *,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> HumanEvaluation:
        """
        Fetches a single evaluation based on its ID.

        Args:
            evaluation_id (str): The ID of the evaluation to fetch.

        Returns:
            HumanEvaluation: The fetched evaluation.

        Parameters
        ----------
        evaluation_id : str

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        HumanEvaluation
            Successful Response

        Examples
        --------
        import asyncio

        from agenta import AsyncAgentaApi

        client = AsyncAgentaApi(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.human_evaluations.fetch_human_evaluation(
                evaluation_id="evaluation_id",
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.fetch_human_evaluation(
            evaluation_id, request_options=request_options
        )
        return _response.data

    async def update_human_evaluation(
        self,
        evaluation_id: str,
        *,
        status: typing.Optional[EvaluationStatusEnum] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> typing.Optional[typing.Any]:
        """
        Updates an evaluation's status.

        Raises:
            HTTPException: If the columns in the test set do not match with the inputs in the variant.

        Returns:
            None: A 204 No Content status code, indicating that the update was successful.

        Parameters
        ----------
        evaluation_id : str

        status : typing.Optional[EvaluationStatusEnum]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        typing.Optional[typing.Any]
            Successful Response

        Examples
        --------
        import asyncio

        from agenta import AsyncAgentaApi

        client = AsyncAgentaApi(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.human_evaluations.update_human_evaluation(
                evaluation_id="evaluation_id",
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.update_human_evaluation(
            evaluation_id, status=status, request_options=request_options
        )
        return _response.data

    async def fetch_human_evaluation_scenarios(
        self,
        evaluation_id: str,
        *,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> typing.List[HumanEvaluationScenario]:
        """
        Fetches evaluation scenarios for a given evaluation ID.

        Arguments:
            evaluation_id (str): The ID of the evaluation for which to fetch scenarios.

        Raises:
            HTTPException: If the evaluation is not found or access is denied.

        Returns:
            List[EvaluationScenario]: A list of evaluation scenarios.

        Parameters
        ----------
        evaluation_id : str

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        typing.List[HumanEvaluationScenario]
            Successful Response

        Examples
        --------
        import asyncio

        from agenta import AsyncAgentaApi

        client = AsyncAgentaApi(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.human_evaluations.fetch_human_evaluation_scenarios(
                evaluation_id="evaluation_id",
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.fetch_human_evaluation_scenarios(
            evaluation_id, request_options=request_options
        )
        return _response.data

    async def update_evaluation_scenario_router(
        self,
        evaluation_id: str,
        evaluation_scenario_id: str,
        evaluation_type: EvaluationType,
        *,
        vote: typing.Optional[str] = OMIT,
        score: typing.Optional[Score] = OMIT,
        correct_answer: typing.Optional[str] = OMIT,
        outputs: typing.Optional[typing.Sequence[HumanEvaluationScenarioOutput]] = OMIT,
        inputs: typing.Optional[typing.Sequence[HumanEvaluationScenarioInput]] = OMIT,
        is_pinned: typing.Optional[bool] = OMIT,
        note: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> typing.Optional[typing.Any]:
        """
        Updates an evaluation scenario's vote or score based on its type.

        Raises:
            HTTPException: If update fails or unauthorized.

        Returns:
            None: 204 No Content status code upon successful update.

        Parameters
        ----------
        evaluation_id : str

        evaluation_scenario_id : str

        evaluation_type : EvaluationType

        vote : typing.Optional[str]

        score : typing.Optional[Score]

        correct_answer : typing.Optional[str]

        outputs : typing.Optional[typing.Sequence[HumanEvaluationScenarioOutput]]

        inputs : typing.Optional[typing.Sequence[HumanEvaluationScenarioInput]]

        is_pinned : typing.Optional[bool]

        note : typing.Optional[str]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        typing.Optional[typing.Any]
            Successful Response

        Examples
        --------
        import asyncio

        from agenta import AsyncAgentaApi

        client = AsyncAgentaApi(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.human_evaluations.update_evaluation_scenario_router(
                evaluation_id="evaluation_id",
                evaluation_scenario_id="evaluation_scenario_id",
                evaluation_type="human_a_b_testing",
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.update_evaluation_scenario_router(
            evaluation_id,
            evaluation_scenario_id,
            evaluation_type,
            vote=vote,
            score=score,
            correct_answer=correct_answer,
            outputs=outputs,
            inputs=inputs,
            is_pinned=is_pinned,
            note=note,
            request_options=request_options,
        )
        return _response.data

    async def get_evaluation_scenario_score_router(
        self,
        evaluation_scenario_id: str,
        *,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> typing.Dict[str, str]:
        """
        Fetch the score of a specific evaluation scenario.

        Args:
            evaluation_scenario_id: The ID of the evaluation scenario to fetch.

        Returns:
            Dictionary containing the scenario ID and its score.

        Parameters
        ----------
        evaluation_scenario_id : str

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        typing.Dict[str, str]
            Successful Response

        Examples
        --------
        import asyncio

        from agenta import AsyncAgentaApi

        client = AsyncAgentaApi(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.human_evaluations.get_evaluation_scenario_score_router(
                evaluation_scenario_id="evaluation_scenario_id",
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.get_evaluation_scenario_score_router(
            evaluation_scenario_id, request_options=request_options
        )
        return _response.data

    async def update_evaluation_scenario_score_router(
        self,
        evaluation_scenario_id: str,
        *,
        score: float,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> typing.Optional[typing.Any]:
        """
        Updates the score of an evaluation scenario.

        Raises:
            HTTPException: Server error if the evaluation update fails.

        Returns:
            None: 204 No Content status code upon successful update.

        Parameters
        ----------
        evaluation_scenario_id : str

        score : float

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        typing.Optional[typing.Any]
            Successful Response

        Examples
        --------
        import asyncio

        from agenta import AsyncAgentaApi

        client = AsyncAgentaApi(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.human_evaluations.update_evaluation_scenario_score_router(
                evaluation_scenario_id="evaluation_scenario_id",
                score=1.1,
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.update_evaluation_scenario_score_router(
            evaluation_scenario_id, score=score, request_options=request_options
        )
        return _response.data

    async def fetch_results(
        self,
        evaluation_id: str,
        *,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> typing.Optional[typing.Any]:
        """
        Fetch all the results for one the comparison table

        Arguments:
            evaluation_id -- _description_

        Returns:
            _description_

        Parameters
        ----------
        evaluation_id : str

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        typing.Optional[typing.Any]
            Successful Response

        Examples
        --------
        import asyncio

        from agenta import AsyncAgentaApi

        client = AsyncAgentaApi(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.human_evaluations.fetch_results(
                evaluation_id="evaluation_id",
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.fetch_results(
            evaluation_id, request_options=request_options
        )
        return _response.data
