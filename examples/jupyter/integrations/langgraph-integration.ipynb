{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrate Agenta with LangGraph (Openinference)\n",
    "\n",
    "This notebook demonstrates how to connect **Agenta** with **LangGraph** for comprehensive observability and debugging of your graph-based LLM applications.\n",
    "\n",
    "> **What is Agenta?** [Agenta](https://agenta.ai) is an open-source LLMOps platform designed to streamline the deployment, management, and scaling of large language models. It offers comprehensive observability, testing, and deployment capabilities for AI applications.\n",
    "\n",
    "> **What is LangGraph?** [LangGraph](https://langchain-ai.github.io/langgraph/) is a library for building stateful, multi-actor applications with LLMs. It extends LangChain's capabilities by enabling the creation of complex workflows as directed graphs where nodes represent different processing steps and edges define the flow between them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation Guide\n",
    "\n",
    "Follow this tutorial to set up LangGraph with Agenta's observability platform for real-time application insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Install Required Dependencies\n",
    "\n",
    "Install the necessary Python packages for this integration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install agenta langchain langgraph langchain-openai langchain-community llama-index openinference-instrumentation-langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Package Descriptions:**\n",
    "- `agenta`: Core SDK for Agenta's prompt engineering and observability platform\n",
    "- `langchain`: Framework for building LLM applications with chains and agents\n",
    "- `langgraph`: Extension for creating graph-based LLM workflows\n",
    "- `langchain-openai`: OpenAI integrations for LangChain\n",
    "- `langchain-community`: Community extensions for LangChain\n",
    "- `llama-index`: Document loading and processing utilities\n",
    "- `openinference-instrumentation-langchain`: Automatic instrumentation library for LangChain operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Setup and Configuration\n",
    "\n",
    "Configure your environment and initialize the Agenta SDK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import agenta as ag\n",
    "from typing import TypedDict, Dict\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_openai import ChatOpenAI\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from openinference.instrumentation.langchain import LangChainInstrumentor\n",
    "\n",
    "\n",
    "# Load configuration from environment\n",
    "os.environ[\"AGENTA_API_KEY\"] = \"your_agenta_api_key\"\n",
    "os.environ[\"AGENTA_HOST\"] = (\n",
    "    \"https://cloud.agenta.ai\"  # Optional, defaults to the Agenta cloud API\n",
    ")\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your_openai_api_key\"  # Required for OpenAI Agents SDK\n",
    "\n",
    "\n",
    "# Start Agenta SDK\n",
    "ag.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What does `ag.init()` do?**\n",
    "This function initializes the Agenta SDK and sets up the necessary configuration for observability. It establishes connection to the Agenta platform, configures tracing and logging settings, and prepares the instrumentation context for your application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Enable LangChain Monitoring\n",
    "\n",
    "Initialize the OpenInference LangChain instrumentation to automatically capture LangGraph operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable LangChain instrumentation (includes LangGraph)\n",
    "LangChainInstrumentor().instrument()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Configure Language Model\n",
    "\n",
    "Set up your language model for the LangGraph workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure ChatOpenAI model\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Build Your Instrumented LangGraph Application\n",
    "\n",
    "Here's a complete example showcasing a meeting transcript analysis workflow with Agenta instrumentation:\n",
    "\n",
    "#### Define State Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define state structure for the graph\n",
    "class SummarizerState(TypedDict):\n",
    "    input: str\n",
    "    segments: Dict[str, list[str]]\n",
    "    speaker_summaries: Dict[str, str]\n",
    "    actions: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Meeting Transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load meeting transcripts from documents\n# Note: Create a 'meetings' directory with .txt or .md files for this to work\ntry:\n    documents = SimpleDirectoryReader(\"meetings\").load_data()\n    full_transcript = \"\\n\".join(doc.text for doc in documents)\nexcept Exception:\n    # Fallback sample transcript for demonstration\n    full_transcript = \"\"\"\nJohn: Good morning everyone, let's start our weekly standup.\nSarah: I finished the user authentication feature yesterday.\nMike: I'm working on the database optimization, should be done by Friday.\nJohn: Great! Sarah, can you help Mike with testing once he's done?\nSarah: Absolutely, I'll be available.\nJohn: Perfect. Our action items are: Sarah to help Mike with testing, and Mike to finish database optimization by Friday.\n\"\"\".strip()\n\nprint(\"Sample transcript loaded:\", full_transcript[:100] + \"...\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Graph Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node 1: Segment speaker contributions\n",
    "def segment_by_speaker(state):\n",
    "    transcript = state[\"input\"]\n",
    "    speakers = {}\n",
    "    for line in transcript.split(\"\\n\"):\n",
    "        if \":\" in line:\n",
    "            name, text = line.split(\":\", 1)\n",
    "            speakers.setdefault(name.strip(), []).append(text.strip())\n",
    "    return {**state, \"segments\": speakers}\n",
    "\n",
    "\n",
    "# Node 2: Summarize each speaker's contributions\n",
    "def summarize_per_speaker(state):\n",
    "    segments = state[\"segments\"]\n",
    "    summaries = {}\n",
    "    for speaker, texts in segments.items():\n",
    "        joined_text = \" \".join(texts)\n",
    "        summary = llm.invoke(f\"Summarize what {speaker} said: {joined_text}\")\n",
    "        summaries[speaker] = summary.content\n",
    "    return {**state, \"speaker_summaries\": summaries}\n",
    "\n",
    "\n",
    "# Node 3: Extract action items\n",
    "def extract_actions(state):\n",
    "    transcript = state[\"input\"]\n",
    "    result = llm.invoke(f\"List all action items from this transcript:\\n{transcript}\")\n",
    "    return {**state, \"actions\": result.content}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Instrumented Analysis Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ag.instrument()\n",
    "def meeting_analyzer(transcript: str):\n",
    "    # Build LangGraph workflow\n",
    "    builder = StateGraph(SummarizerState)\n",
    "    builder.add_node(\"segment\", RunnableLambda(segment_by_speaker))\n",
    "    builder.add_node(\"summarize\", RunnableLambda(summarize_per_speaker))\n",
    "    builder.add_node(\"extract_actions\", RunnableLambda(extract_actions))\n",
    "\n",
    "    builder.set_entry_point(\"segment\")\n",
    "    builder.add_edge(\"segment\", \"summarize\")\n",
    "    builder.add_edge(\"summarize\", \"extract_actions\")\n",
    "    builder.add_edge(\"extract_actions\", END)\n",
    "\n",
    "    graph = builder.compile()\n",
    "    result = graph.invoke({\"input\": transcript})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "result = meeting_analyzer(full_transcript)\n",
    "print(\"Analysis Result:\")\n",
    "print(\"Segments:\", result[\"segments\"])\n",
    "print(\"\\nSpeaker Summaries:\", result[\"speaker_summaries\"])\n",
    "print(\"\\nAction Items:\", result[\"actions\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Understanding the @ag.instrument() Decorator\n",
    "\n",
    "The `@ag.instrument()` decorator automatically captures all input and output data from your function, enabling comprehensive observability without manual instrumentation.\n",
    "\n",
    "**Span Type Configuration:**\n",
    "Use the `spankind` parameter to categorize operations in Agenta WebUI. Available options:\n",
    "\n",
    "- `agent` - Autonomous agent behaviors\n",
    "- `chain` - Sequential processing workflows\n",
    "- `workflow` - Complete application processes (default)\n",
    "- `tool` - Utility and helper functions\n",
    "- `embedding` - Vector embedding operations\n",
    "- `query` - Search and retrieval tasks\n",
    "- `completion` - Text generation operations\n",
    "- `chat` - Conversational interfaces\n",
    "- `rerank` - Result ordering operations\n",
    "\n",
    "**Standard Behavior:**\n",
    "By default, when `spankind` is not specified, the operation becomes a root-level span, categorized as a `workflow` in Agenta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example with custom span classification:\n",
    "@ag.instrument(spankind=\"chain\")\n",
    "def document_processing_chain(documents: list):\n",
    "    # Document processing workflow\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: View Traces in Agenta\n",
    "\n",
    "After running your application, access detailed execution traces through Agenta's dashboard. The observability data includes:\n",
    "\n",
    "- Complete graph workflow execution timeline\n",
    "- Individual node processing steps and state transitions\n",
    "- LLM invocations and response generation\n",
    "- State updates and data flow between nodes\n",
    "- Document loading and preprocessing operations\n",
    "- Performance metrics and timing analysis\n",
    "\n",
    "\n",
    "<img \n",
    "    style=\"display: block; margin: 20px; text-align: center\"\n",
    "    src=\"./images/agenta-openinference-langgraph-trace.png\"\n",
    "    width=\"90%\"\n",
    "    alt=\"Agenta dashboard showing LangGraph application trace with detailed execution steps\">\n",
    "\n",
    "\n",
    "The observability interface provides insights for:\n",
    "- Debug complex graph workflows and state management\n",
    "- Monitor node execution performance and bottlenecks\n",
    "- Analyze LLM usage patterns and token consumption\n",
    "- Track data flow and state transitions between nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Usage\n",
    "\n",
    "### Custom Span Configuration\n",
    "\n",
    "Customize instrumentation for different application components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ag.instrument(spankind=\"workflow\")\n",
    "def document_analysis_pipeline(file_path: str):\n",
    "    return meeting_analyzer(file_path)\n",
    "\n",
    "\n",
    "@ag.instrument(spankind=\"tool\")\n",
    "def custom_document_loader(directory: str):\n",
    "    # Custom document loading logic\n",
    "    pass\n",
    "\n",
    "\n",
    "@ag.instrument(spankind=\"chain\")\n",
    "def multi_step_analysis(transcript: str):\n",
    "    # Multi-step analysis workflow\n",
    "    return transcript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real-world Examples\n",
    "\n",
    "#### Customer Feedback Analysis System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedbackState(TypedDict):\n",
    "    input: str\n",
    "    sentiment: str\n",
    "    categories: list[str]\n",
    "    priority: str\n",
    "    response_draft: str\n",
    "\n",
    "\n",
    "def analyze_sentiment(state):\n",
    "    feedback = state[\"input\"]\n",
    "    result = llm.invoke(f\"Analyze sentiment of this feedback: {feedback}\")\n",
    "    return {**state, \"sentiment\": result.content}\n",
    "\n",
    "\n",
    "def categorize_feedback(state):\n",
    "    feedback = state[\"input\"]\n",
    "    result = llm.invoke(f\"Categorize this feedback into relevant topics: {feedback}\")\n",
    "    return {**state, \"categories\": result.content.split(\", \")}\n",
    "\n",
    "\n",
    "def determine_priority(state):\n",
    "    sentiment = state[\"sentiment\"]\n",
    "    categories = state[\"categories\"]\n",
    "    result = llm.invoke(\n",
    "        f\"Determine priority (high/medium/low) based on sentiment: {sentiment} and categories: {categories}\"\n",
    "    )\n",
    "    return {**state, \"priority\": result.content}\n",
    "\n",
    "\n",
    "def draft_response(state):\n",
    "    feedback = state[\"input\"]\n",
    "    sentiment = state[\"sentiment\"]\n",
    "    result = llm.invoke(\n",
    "        f\"Draft a professional response to this {sentiment} feedback: {feedback}\"\n",
    "    )\n",
    "    return {**state, \"response_draft\": result.content}\n",
    "\n",
    "\n",
    "@ag.instrument(spankind=\"workflow\")\n",
    "def feedback_processor(feedback_text: str):\n",
    "    builder = StateGraph(FeedbackState)\n",
    "    builder.add_node(\"sentiment\", RunnableLambda(analyze_sentiment))\n",
    "    builder.add_node(\"categorize\", RunnableLambda(categorize_feedback))\n",
    "    builder.add_node(\"priority\", RunnableLambda(determine_priority))\n",
    "    builder.add_node(\"response\", RunnableLambda(draft_response))\n",
    "\n",
    "    builder.set_entry_point(\"sentiment\")\n",
    "    builder.add_edge(\"sentiment\", \"categorize\")\n",
    "    builder.add_edge(\"categorize\", \"priority\")\n",
    "    builder.add_edge(\"priority\", \"response\")\n",
    "    builder.add_edge(\"response\", END)\n",
    "\n",
    "    graph = builder.compile()\n",
    "    return graph.invoke({\"input\": feedback_text})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Customer Feedback Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test feedback analysis\n",
    "sample_feedback = \"Your product is amazing but the customer service was terrible. I waited 2 hours on hold!\"\n",
    "feedback_result = feedback_processor(sample_feedback)\n",
    "print(\"Feedback Analysis Result:\")\n",
    "print(\"Sentiment:\", feedback_result[\"sentiment\"])\n",
    "print(\"Categories:\", feedback_result[\"categories\"])\n",
    "print(\"Priority:\", feedback_result[\"priority\"])\n",
    "print(\"Response Draft:\", feedback_result[\"response_draft\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Research Paper Analysis Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "class ResearchState(TypedDict):\n    input: str\n    abstract_summary: str\n    key_findings: list[str]\n    methodology: str\n    limitations: str\n    relevance_score: float\n\n\n@ag.instrument(spankind=\"chain\")\ndef research_analyzer(paper_text: str):\n    def extract_abstract(state):\n        paper = state[\"input\"]\n        result = llm.invoke(\n            f\"Extract and summarize the abstract from this research paper: {paper}\"\n        )\n        return {**state, \"abstract_summary\": result.content}\n\n    def identify_findings(state):\n        paper = state[\"input\"]\n        result = llm.invoke(f\"List the key findings from this research paper: {paper}\")\n        return {**state, \"key_findings\": result.content.split(\"\\n\")}\n\n    def analyze_methodology(state):\n        paper = state[\"input\"]\n        result = llm.invoke(f\"Describe the methodology used in this research: {paper}\")\n        return {**state, \"methodology\": result.content}\n\n    def assess_limitations(state):\n        paper = state[\"input\"]\n        result = llm.invoke(f\"Identify limitations mentioned in this research: {paper}\")\n        return {**state, \"limitations\": result.content}\n\n    def score_relevance(state):\n        abstract = state[\"abstract_summary\"]\n        result = llm.invoke(\n            f\"Rate the relevance of this research on a scale of 0-10: {abstract}\"\n        )\n        try:\n            score = float(result.content.strip())\n        except Exception:\n            score = 5.0\n        return {**state, \"relevance_score\": score}\n\n    builder = StateGraph(ResearchState)\n    builder.add_node(\"abstract\", RunnableLambda(extract_abstract))\n    builder.add_node(\"findings\", RunnableLambda(identify_findings))\n    builder.add_node(\"methodology\", RunnableLambda(analyze_methodology))\n    builder.add_node(\"limitations\", RunnableLambda(assess_limitations))\n    builder.add_node(\"relevance\", RunnableLambda(score_relevance))\n\n    builder.set_entry_point(\"abstract\")\n    builder.add_edge(\"abstract\", \"findings\")\n    builder.add_edge(\"findings\", \"methodology\")\n    builder.add_edge(\"methodology\", \"limitations\")\n    builder.add_edge(\"limitations\", \"relevance\")\n    builder.add_edge(\"relevance\", END)\n\n    graph = builder.compile()\n    return graph.invoke({\"input\": paper_text})"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Content Moderation Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "class ModerationState(TypedDict):\n    input: str\n    toxicity_score: float\n    content_categories: list[str]\n    action_required: str\n    explanation: str\n\n\n@ag.instrument(spankind=\"workflow\")\ndef content_moderator(user_content: str):\n    def assess_toxicity(state):\n        content = state[\"input\"]\n        result = llm.invoke(f\"Rate toxicity of this content from 0-10: {content}\")\n        try:\n            score = float(result.content.strip())\n        except Exception:\n            score = 0.0\n        return {**state, \"toxicity_score\": score}\n\n    def categorize_content(state):\n        content = state[\"input\"]\n        result = llm.invoke(\n            f\"Categorize this content (spam, harassment, hate speech, etc.): {content}\"\n        )\n        return {**state, \"content_categories\": result.content.split(\", \")}\n\n    def determine_action(state):\n        toxicity = state[\"toxicity_score\"]\n        categories = state[\"content_categories\"]\n        if toxicity > 7:\n            action = \"remove\"\n        elif toxicity > 4:\n            action = \"flag_for_review\"\n        else:\n            action = \"approve\"\n        explanation = (\n            f\"Decision based on toxicity score: {toxicity} and categories: {categories}\"\n        )\n        return {**state, \"action_required\": action, \"explanation\": explanation}\n\n    builder = StateGraph(ModerationState)\n    builder.add_node(\"toxicity\", RunnableLambda(assess_toxicity))\n    builder.add_node(\"categorize\", RunnableLambda(categorize_content))\n    builder.add_node(\"action\", RunnableLambda(determine_action))\n\n    builder.set_entry_point(\"toxicity\")\n    builder.add_edge(\"toxicity\", \"categorize\")\n    builder.add_edge(\"categorize\", \"action\")\n    builder.add_edge(\"action\", END)\n\n    graph = builder.compile()\n    return graph.invoke({\"input\": user_content})"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Content Moderation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test content moderation\n",
    "sample_content = \"This is a great product, I highly recommend it to everyone!\"\n",
    "moderation_result = content_moderator(sample_content)\n",
    "print(\"Content Moderation Result:\")\n",
    "print(\"Toxicity Score:\", moderation_result[\"toxicity_score\"])\n",
    "print(\"Categories:\", moderation_result[\"content_categories\"])\n",
    "print(\"Action Required:\", moderation_result[\"action_required\"])\n",
    "print(\"Explanation:\", moderation_result[\"explanation\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "For more detailed information about Agenta's observability features and advanced configuration options, visit the [Agenta Observability SDK Documentation](/observability/observability-sdk)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}