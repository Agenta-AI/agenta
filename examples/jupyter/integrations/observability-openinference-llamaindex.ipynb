{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrate Agenta with LlamaIndex (Openinference)\n",
    "\n",
    "This notebook demonstrates how to connect **Agenta** with **LlamaIndex** for comprehensive observability and debugging of your LLM applications.\n",
    "\n",
    "> **What is Agenta?** [Agenta](https://agenta.ai) is an open-source LLMOps platform designed to streamline the deployment, management, and scaling of large language models. It offers comprehensive observability, testing, and deployment capabilities for AI applications.\n",
    "\n",
    "> **What is LlamaIndex?** [LlamaIndex](https://www.llamaindex.ai/) ([GitHub](https://github.com/run-llama/llama_index)) is a powerful data framework that connects LLMs with your private data sources. It simplifies working with various data formats and creates searchable indices for context-aware AI applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation Guide\n",
    "\n",
    "Follow this tutorial to set up LlamaIndex with Agenta's observability platform for real-time application insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Install Required Dependencies\n",
    "\n",
    "Install the necessary Python packages for this integration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install agenta llama_index openinference-instrumentation-llama_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Package Descriptions:**\n",
    "- `agenta`: Core SDK for Agenta's prompt engineering and observability platform\n",
    "- `llama_index`: Framework for building data-connected LLM applications\n",
    "- `openinference-instrumentation-llama_index`: Automatic instrumentation library for LlamaIndex operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Setup and Configuration\n",
    "\n",
    "Configure your environment and initialize the Agenta SDK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import agenta as ag\n",
    "\n",
    "\n",
    "# Load configuration from environment\n",
    "os.environ[\"AGENTA_API_KEY\"] = \"your_agenta_api_key\"\n",
    "os.environ[\n",
    "    \"AGENTA_HOST\"\n",
    "] = \"https://cloud.agenta.ai\"  # Optional, defaults to the Agenta cloud API\n",
    "\n",
    "\n",
    "# Start Agenta SDK\n",
    "ag.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What does `ag.init()` do?**\n",
    "This function initializes the Agenta SDK and sets up the necessary configuration for observability. It establishes connection to the Agenta platform, configures tracing and logging settings, and prepares the instrumentation context for your application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Enable LlamaIndex Monitoring\n",
    "\n",
    "Initialize the OpenInference LlamaIndex instrumentation to automatically capture LlamaIndex operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openinference.instrumentation.llama_index import LlamaIndexInstrumentor\n",
    "\n",
    "# Activate LlamaIndex monitoring\n",
    "LlamaIndexInstrumentor().instrument()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Build Your Instrumented Application\n",
    "\n",
    "Here's a complete example of a LlamaIndex application with Agenta instrumentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import agenta as ag\n",
    "from openinference.instrumentation.llama_index import LlamaIndexInstrumentor\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "\n",
    "\n",
    "# Configuration setup\n",
    "os.environ[\"AGENTA_API_KEY\"] = \"your_agenta_api_key\"\n",
    "os.environ[\n",
    "    \"AGENTA_HOST\"\n",
    "] = \"https://cloud.agenta.ai\"  # Optional, defaults to the Agenta cloud API\n",
    "\n",
    "# Initialize observability\n",
    "ag.init()\n",
    "\n",
    "# Enable LlamaIndex instrumentation\n",
    "LlamaIndexInstrumentor().instrument()\n",
    "\n",
    "\n",
    "@ag.instrument()\n",
    "def document_search_app(user_query: str):\n",
    "    \"\"\"\n",
    "    Document search application using LlamaIndex.\n",
    "    Loads documents, builds a searchable index, and answers user queries.\n",
    "    \"\"\"\n",
    "    # Load documents from local directory\n",
    "    docs = SimpleDirectoryReader(\"data\").load_data()\n",
    "\n",
    "    # Build vector search index\n",
    "    search_index = VectorStoreIndex.from_documents(docs)\n",
    "\n",
    "    # Initialize query processor\n",
    "    query_processor = search_index.as_query_engine()\n",
    "\n",
    "    # Process user query\n",
    "    answer = query_processor.query(user_query)\n",
    "\n",
    "    return answer\n",
    "\n",
    "\n",
    "# Run the application\n",
    "if __name__ == \"__main__\":\n",
    "    result = document_search_app(\"What is Agenta?\")\n",
    "    print(f\"Answer: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Understanding the @ag.instrument() Decorator\n",
    "\n",
    "The `@ag.instrument()` decorator automatically captures all input and output data from your function, enabling comprehensive observability without manual instrumentation.\n",
    "\n",
    "**Span Type Configuration:**\n",
    "Use the `spankind` parameter to categorize operations in Agenta WebUI. Available options:\n",
    "\n",
    "- `agent` - Autonomous agent behaviors\n",
    "- `chain` - Sequential processing workflows\n",
    "- `workflow` - Complete application processes (default)\n",
    "- `tool` - Utility and helper functions\n",
    "- `embedding` - Vector embedding operations\n",
    "- `query` - Search and retrieval tasks\n",
    "- `completion` - Text generation operations\n",
    "- `chat` - Conversational interfaces\n",
    "- `rerank` - Result ordering operations\n",
    "\n",
    "**Standard Behavior:**\n",
    "By default, when `spankind` is not specified, the operation becomes a root-level span, categorized as a `workflow` in Agenta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example with custom span classification:\n",
    "@ag.instrument(spankind=\"query\")\n",
    "def search_knowledge_base(search_term: str):\n",
    "    # Knowledge base search implementation\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: View Traces in Agenta\n",
    "\n",
    "After running your application, access detailed execution traces through Agenta's dashboard. The observability data includes:\n",
    "\n",
    "- Complete workflow execution timeline\n",
    "- Document loading and indexing processes\n",
    "- Vector search operations and retrieval steps\n",
    "- Query processing and response generation\n",
    "- Performance metrics and timing analysis\n",
    "\n",
    "\n",
    "<img \n",
    "    style=\"display: block; margin: 20px; text-align: center\"\n",
    "    src=\"./images/agenta-openinference-llamaindex-trace.png\"\n",
    "    width=\"90%\"\n",
    "    alt=\"Agenta dashboard showing LlamaIndex application trace with detailed execution steps\">\n",
    "\n",
    "\n",
    "The observability interface provides insights for:\n",
    "- Performance optimization opportunities\n",
    "- Query pattern analysis\n",
    "- Document retrieval validation\n",
    "- Application behavior tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "For more detailed information about Agenta's observability features and advanced configuration options, visit the [Agenta Observability SDK Documentation](/observability/observability-sdk)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
