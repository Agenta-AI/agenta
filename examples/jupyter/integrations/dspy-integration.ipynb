{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrate Agenta with DSPy\n",
    "\n",
    "This notebook demonstrates how to connect **Agenta** with **DSPy** for comprehensive observability and debugging of your LLM applications.\n",
    "\n",
    "> **What is Agenta?** [Agenta](https://agenta.ai) is an open-source LLMOps platform designed to streamline the deployment, management, and scaling of large language models. It offers comprehensive observability, testing, and deployment capabilities for AI applications.\n",
    "\n",
    "> **What is DSPy?** [DSPy](https://dspy-docs.vercel.app/) ([GitHub](https://github.com/stanfordnlp/dspy)) is a framework for algorithmically optimizing LM prompts and weights. It provides composable and declarative modules for instructing language models in a more systematic way than traditional prompting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation Guide\n",
    "\n",
    "Follow this tutorial to set up DSPy with Agenta's observability platform for real-time application insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Install Required Dependencies\n",
    "\n",
    "Install the necessary Python packages for this integration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install agenta dspy openinference-instrumentation-dspy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Package Descriptions:**\n",
    "- `agenta`: Core SDK for Agenta's prompt engineering and observability platform\n",
    "- `dspy`: Framework for building systematic LLM applications with prompt optimization\n",
    "- `openinference-instrumentation-dspy`: Automatic instrumentation library for DSPy operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Setup and Configuration\n",
    "\n",
    "Configure your environment and initialize the Agenta SDK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import agenta as ag\n",
    "import dspy\n",
    "from openinference.instrumentation.dspy import DSPyInstrumentor\n",
    "\n",
    "\n",
    "# Load configuration from environment\n",
    "os.environ[\"AGENTA_API_KEY\"] = \"your_agenta_api_key\"\n",
    "os.environ[\"AGENTA_HOST\"] = (\n",
    "    \"https://cloud.agenta.ai\"  # Optional, defaults to the Agenta cloud API\n",
    ")\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your_openai_api_key\"  # Required for OpenAI models\n",
    "\n",
    "\n",
    "# Start Agenta SDK\n",
    "ag.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What does `ag.init()` do?**\n",
    "This function initializes the Agenta SDK and sets up the necessary configuration for observability. It establishes connection to the Agenta platform, configures tracing and logging settings, and prepares the instrumentation context for your application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Enable DSPy Monitoring\n",
    "\n",
    "Initialize the OpenInference DSPy instrumentation to automatically capture DSPy operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activate DSPy monitoring\n",
    "DSPyInstrumentor().instrument()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Configure DSPy Language Model\n",
    "\n",
    "Set up your DSPy language model configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure DSPy with your preferred language model\n",
    "lm = dspy.LM(\"openai/gpt-4o\")\n",
    "dspy.configure(lm=lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Build Your Instrumented Application\n",
    "\n",
    "Here's a complete example showcasing multiple DSPy use cases with Agenta instrumentation:\n",
    "\n",
    "#### Use Case 1: Math Reasoning with Chain of Thought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ag.instrument()\n",
    "def math_reasoning(question: str):\n",
    "    cot = dspy.ChainOfThought(\"question -> answer: float\")\n",
    "    response = cot(question=question)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Case 2: Retrieval-Augmented Generation (RAG) with Wikipedia Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ag.instrument(spankind=\"query\")\n",
    "def search_wikipedia(query: str) -> list[str]:\n",
    "    results = dspy.ColBERTv2(url=\"http://20.102.90.50:2017/wiki17_abstracts\")(\n",
    "        query, k=3\n",
    "    )\n",
    "    return [x[\"text\"] for x in results]\n",
    "\n",
    "\n",
    "@ag.instrument()\n",
    "def rag(question: str):\n",
    "    cot = dspy.ChainOfThought(\"context, question -> response\")\n",
    "    response = cot(context=search_wikipedia(question), question=question)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Case 3: Article Generation with Outline and Sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Outline(dspy.Signature):\n",
    "    \"\"\"Outline a thorough overview of a topic.\"\"\"\n",
    "    \n",
    "    topic: str = dspy.InputField()\n",
    "    title: str = dspy.OutputField()\n",
    "    sections: list[str] = dspy.OutputField()\n",
    "    section_subheadings: dict[str, list[str]] = dspy.OutputField(\n",
    "        desc=\"mapping from section headings to subheadings\"\n",
    "    )\n",
    "\n",
    "\n",
    "class DraftSection(dspy.Signature):\n",
    "    \"\"\"Draft a top-level section of an article.\"\"\"\n",
    "    \n",
    "    topic: str = dspy.InputField()\n",
    "    section_heading: str = dspy.InputField()\n",
    "    section_subheadings: list[str] = dspy.InputField()\n",
    "    content: str = dspy.OutputField(desc=\"markdown-formatted section\")\n",
    "\n",
    "\n",
    "class DraftArticle(dspy.Module):\n",
    "    def __init__(self):\n",
    "        self.build_outline = dspy.ChainOfThought(Outline)\n",
    "        self.draft_section = dspy.ChainOfThought(DraftSection)\n",
    "    \n",
    "    def forward(self, topic):\n",
    "        outline = self.build_outline(topic=topic)\n",
    "        sections = []\n",
    "        for heading, subheadings in outline.section_subheadings.items():\n",
    "            section, subheadings = f\"## {heading}\", [\n",
    "                f\"### {subheading}\" for subheading in subheadings\n",
    "            ]\n",
    "            section = self.draft_section(\n",
    "                topic=outline.title,\n",
    "                section_heading=section,\n",
    "                section_subheadings=subheadings,\n",
    "            )\n",
    "            sections.append(section.content)\n",
    "        return dspy.Prediction(title=outline.title, sections=sections)\n",
    "\n",
    "\n",
    "@ag.instrument()\n",
    "def journalist(topic: str):\n",
    "    draft_article = DraftArticle()\n",
    "    article = draft_article(topic=topic)\n",
    "    return article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use case 1: Chain of Thought reasoning\n",
    "response = math_reasoning(\"What is 2 + 2?\")\n",
    "print(\"Chain of Thought response:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use case 2: RAG with Wikipedia\n",
    "rag_response = rag(\"What's the name of the castle that David Gregory inherited?\")\n",
    "print(\"RAG response:\", rag_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use case 3: Article generation\n",
    "article = journalist(\"The impact of AI on society\")\n",
    "print(\"Article generation response:\", article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Understanding the @ag.instrument() Decorator\n",
    "\n",
    "The `@ag.instrument()` decorator automatically captures all input and output data from your function, enabling comprehensive observability without manual instrumentation.\n",
    "\n",
    "**Span Type Configuration:**\n",
    "Use the `spankind` parameter to categorize operations in Agenta WebUI. Available options:\n",
    "\n",
    "- `agent` - Autonomous agent behaviors\n",
    "- `chain` - Sequential processing workflows\n",
    "- `workflow` - Complete application processes (default)\n",
    "- `tool` - Utility and helper functions\n",
    "- `embedding` - Vector embedding operations\n",
    "- `query` - Search and retrieval tasks\n",
    "- `completion` - Text generation operations\n",
    "- `chat` - Conversational interfaces\n",
    "- `rerank` - Result ordering operations\n",
    "\n",
    "**Standard Behavior:**\n",
    "By default, when `spankind` is not specified, the operation becomes a root-level span, categorized as a `workflow` in Agenta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example with custom span classification:\n",
    "@ag.instrument(spankind=\"query\")\n",
    "def search_knowledge_base(search_term: str):\n",
    "    # Knowledge base search implementation\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: View Traces in Agenta\n",
    "\n",
    "After running your application, access detailed execution traces through Agenta's dashboard. The observability data includes:\n",
    "\n",
    "- Complete workflow execution timeline\n",
    "- DSPy module initialization and configuration steps\n",
    "- Chain of Thought reasoning processes\n",
    "- Retrieval operations and context augmentation\n",
    "- Language model calls and response generation\n",
    "- Performance metrics and timing analysis\n",
    "\n",
    "\n",
    "<img \n",
    "    style=\"display: block; margin: 20px; text-align: center\"\n",
    "    src=\"./images/agenta-openinference-dspy-trace.png\"\n",
    "    width=\"90%\"\n",
    "    alt=\"Agenta dashboard showing DSPy application trace with detailed execution steps\">\n",
    "\n",
    "\n",
    "The observability interface provides insights for:\n",
    "- Debug complex reasoning chains and prompt optimization\n",
    "- Monitor retrieval effectiveness and context quality\n",
    "- Analyze language model performance and token usage\n",
    "- Track application behavior trends and optimization opportunities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "For more detailed information about Agenta's observability features and advanced configuration options, visit the [Agenta Observability SDK Documentation](/observability/observability-sdk)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
