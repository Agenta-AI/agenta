{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrate Agenta with PydanticAI Logfire\n",
    "\n",
    "This notebook demonstrates how to connect **Agenta** with **PydanticAI** and **Logfire** for comprehensive observability and debugging of your AI agent applications.\n",
    "\n",
    "> **What is Agenta?** [Agenta](https://agenta.ai) is an open-source LLMOps platform designed to streamline the deployment, management, and scaling of large language models. It offers comprehensive observability, testing, and deployment capabilities for AI applications.\n",
    "\n",
    "> **What is PydanticAI?** [PydanticAI](https://ai.pydantic.dev/) is a Python agent framework designed to make it less painful to build production-grade applications with generative AI. It provides type safety, structured outputs, and dependency injection for building robust AI agents.\n",
    "\n",
    "> **What is Logfire?** [Logfire](https://logfire.pydantic.dev/) is an observability platform from Pydantic that provides structured logging and tracing capabilities, specifically designed to work seamlessly with PydanticAI applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation Guide\n",
    "\n",
    "Follow this tutorial to set up PydanticAI with Logfire and Agenta's observability platform for real-time application insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Install Required Dependencies\n",
    "\n",
    "Install the necessary Python packages for this integration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pydantic-ai[examples] logfire agenta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Package Descriptions:**\n",
    "- `pydantic-ai[examples]`: The PydanticAI framework with example dependencies\n",
    "- `logfire`: Pydantic's observability platform for structured logging and tracing\n",
    "- `agenta`: Core SDK for Agenta's prompt engineering and observability platform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Setup and Configuration\n",
    "\n",
    "Configure your environment and initialize both Agenta and Logfire:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dataclasses import dataclass\n",
    "from pydantic import BaseModel, Field\n",
    "from pydantic_ai import Agent, RunContext\n",
    "import logfire\n",
    "import agenta as ag\n",
    "\n",
    "# Load configuration from environment\n",
    "os.environ[\"AGENTA_API_KEY\"] = \"your_agenta_api_key\"\n",
    "os.environ[\n",
    "    \"AGENTA_HOST\"\n",
    "] = \"https://cloud.agenta.ai\"  # Optional, defaults to the Agenta cloud API\n",
    "\n",
    "# Initialize Agenta SDK\n",
    "ag.init()\n",
    "\n",
    "# Configure Logfire for local development\n",
    "logfire.configure(\n",
    "    service_name=\"my_logfire_service\", send_to_logfire=False, scrubbing=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What does `ag.init()` do?**\n",
    "This function initializes the Agenta SDK and sets up the necessary configuration for observability. It establishes connection to the Agenta platform, configures tracing and logging settings, and prepares the instrumentation context for your application.\n",
    "\n",
    "**Logfire Configuration:**\n",
    "The `logfire.configure()` function sets up Logfire's observability features. Setting `send_to_logfire=False` keeps traces local for development, while `scrubbing=False` preserves all data for debugging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Enable PydanticAI Instrumentation\n",
    "\n",
    "PydanticAI comes with built-in observability support that integrates with OpenTelemetry-compatible systems:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable automatic instrumentation for async database operations\n",
    "logfire.instrument_asyncpg()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Build Your Instrumented PydanticAI Application\n",
    "\n",
    "Here's a complete example showcasing a banking support agent with Agenta instrumentation:\n",
    "\n",
    "#### Create Mock Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mock database for demonstration\n",
    "class DatabaseConn:\n",
    "    \"\"\"Fake database for example purposes.\"\"\"\n",
    "\n",
    "    @classmethod\n",
    "    async def customer_name(cls, *, id: int) -> str | None:\n",
    "        if id == 123:\n",
    "            return \"John\"\n",
    "        return None\n",
    "\n",
    "    @classmethod\n",
    "    async def customer_balance(cls, *, id: int, include_pending: bool) -> float:\n",
    "        if id == 123 and include_pending:\n",
    "            return 123.45\n",
    "        else:\n",
    "            raise ValueError(\"Customer not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Dependencies and Output Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies for the support agent\n",
    "@dataclass\n",
    "class SupportDependencies:\n",
    "    customer_id: int\n",
    "    including_pending: bool\n",
    "    db: DatabaseConn\n",
    "\n",
    "\n",
    "# Structured output model\n",
    "class SupportOutput(BaseModel):\n",
    "    support_advice: str = Field(description=\"Advice returned to the customer\")\n",
    "    block_card: bool = Field(description=\"Whether to block their card or not\")\n",
    "    risk: int = Field(description=\"Risk level of query\", ge=0, le=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the Support Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the support agent with instrumentation\n",
    "support_agent = Agent(\n",
    "    \"openai:gpt-4o\",\n",
    "    deps_type=SupportDependencies,\n",
    "    output_type=SupportOutput,\n",
    "    system_prompt=(\n",
    "        \"You are a support agent in our bank, give the \"\n",
    "        \"customer support and judge the risk level of their query. \"\n",
    "        \"Reply using the customer's name.\"\n",
    "    ),\n",
    "    instrument=True,  # Enable built-in PydanticAI instrumentation\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add Dynamic System Prompt and Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamic system prompt with customer context\n",
    "@support_agent.system_prompt\n",
    "async def add_customer_name(ctx: RunContext[SupportDependencies]) -> str:\n",
    "    customer_name = await ctx.deps.db.customer_name(id=ctx.deps.customer_id)\n",
    "    return f\"The customer's name is {customer_name!r}\"\n",
    "\n",
    "\n",
    "# Agent tool for balance inquiries\n",
    "@support_agent.tool\n",
    "async def customer_balance(ctx: RunContext[SupportDependencies]) -> str:\n",
    "    \"\"\"Returns the customer's current account balance.\"\"\"\n",
    "    balance = await ctx.deps.db.customer_balance(\n",
    "        id=ctx.deps.customer_id,\n",
    "        include_pending=ctx.deps.including_pending,\n",
    "    )\n",
    "    return f\"${balance:.2f}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Agenta-Instrumented Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agenta-instrumented functions\n",
    "@ag.instrument()\n",
    "def bank_balance(customer_id: int, query: str, include_pending: bool = True):\n",
    "    \"\"\"Returns the customer's current account balance.\"\"\"\n",
    "    deps = SupportDependencies(\n",
    "        customer_id=customer_id,\n",
    "        including_pending=include_pending,\n",
    "        db=DatabaseConn(),\n",
    "    )\n",
    "    result = support_agent.run_sync(query, deps=deps)\n",
    "    return result\n",
    "\n",
    "\n",
    "@ag.instrument()\n",
    "def block_card(customer_id: int, query: str, include_pending: bool = True):\n",
    "    \"\"\"Blocks the customer's card if they report it lost.\"\"\"\n",
    "    deps = SupportDependencies(\n",
    "        customer_id=customer_id,\n",
    "        including_pending=include_pending,\n",
    "        db=DatabaseConn(),\n",
    "    )\n",
    "    result = support_agent.run_sync(query, deps=deps)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the Banking Support Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "# Agent 1: get user's account balance\n",
    "result = bank_balance(123, \"What is my balance?\", True)\n",
    "print(\"Balance Query Result:\")\n",
    "print(f\"Advice: {result.output.support_advice}\")\n",
    "print(f\"Risk Level: {result.output.risk}\")\n",
    "print(f\"Block Card: {result.output.block_card}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent 2: block user's card if they report it lost\n",
    "result = block_card(123, \"I just lost my card!\", True)\n",
    "print(\"Card Block Result:\")\n",
    "print(f\"Advice: {result.output.support_advice}\")\n",
    "print(f\"Risk Level: {result.output.risk}\")\n",
    "print(f\"Block Card: {result.output.block_card}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Understanding the @ag.instrument() Decorator\n",
    "\n",
    "The `@ag.instrument()` decorator automatically captures all input and output data from your function, enabling comprehensive observability without manual instrumentation.\n",
    "\n",
    "**Span Type Configuration:**\n",
    "Use the `spankind` parameter to categorize operations in Agenta WebUI. Available options:\n",
    "\n",
    "- `agent` - Autonomous agent behaviors\n",
    "- `chain` - Sequential processing workflows\n",
    "- `workflow` - Complete application processes (default)\n",
    "- `tool` - Utility and helper functions\n",
    "- `embedding` - Vector embedding operations\n",
    "- `query` - Search and retrieval tasks\n",
    "- `completion` - Text generation operations\n",
    "- `chat` - Conversational interfaces\n",
    "- `rerank` - Result ordering operations\n",
    "\n",
    "**Standard Behavior:**\n",
    "By default, when `spankind` is not specified, the operation becomes a root-level span, categorized as a `workflow` in Agenta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example with custom span classification:\n",
    "@ag.instrument(spankind=\"agent\")\n",
    "def customer_service_agent(query: str):\n",
    "    # Agent-specific logic implementation\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: View Traces in Agenta\n",
    "\n",
    "After running your application, access detailed execution traces through Agenta's dashboard. The observability data includes:\n",
    "\n",
    "- Complete agent workflow execution timeline\n",
    "- PydanticAI agent initialization and configuration\n",
    "- Tool function calls and dependency injection\n",
    "- LLM interactions and structured output validation\n",
    "- Database queries and external service calls\n",
    "- Performance metrics and timing analysis\n",
    "\n",
    "<img \n",
    "    style=\"display: block; margin: 20px; text-align: center\"\n",
    "    src=\"./images/agenta-pydanticai-logfire-trace.png\"\n",
    "    width=\"90%\"\n",
    "    alt=\"Agenta dashboard showing PydanticAI application trace with detailed execution steps\">\n",
    "\n",
    "The observability interface provides insights for:\n",
    "- Debug complex agent interactions and tool usage\n",
    "- Monitor dependency injection and context management\n",
    "- Analyze LLM performance and structured output validation\n",
    "- Track database queries and external API calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Usage\n",
    "\n",
    "### Custom Span Configuration\n",
    "\n",
    "Customize instrumentation for different application components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ag.instrument(spankind=\"workflow\")\n",
    "def customer_support_pipeline(customer_id: int, query: str):\n",
    "    return bank_balance(customer_id, query)\n",
    "\n",
    "\n",
    "@ag.instrument(spankind=\"tool\")\n",
    "def external_api_integration(data: dict):\n",
    "    # External API call logic\n",
    "    pass\n",
    "\n",
    "\n",
    "@ag.instrument(spankind=\"agent\")\n",
    "def specialized_banking_agent(context: dict):\n",
    "    # Specialized agent implementation\n",
    "    return context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real-world Examples\n",
    "\n",
    "#### Multi-Agent Customer Service System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomerServiceDeps:\n",
    "    def __init__(self, customer_id: int, db: DatabaseConn):\n",
    "        self.customer_id = customer_id\n",
    "        self.db = db\n",
    "\n",
    "\n",
    "class ServiceOutput(BaseModel):\n",
    "    response: str = Field(description=\"Customer service response\")\n",
    "    escalate: bool = Field(description=\"Whether to escalate to human agent\")\n",
    "    satisfaction_score: int = Field(description=\"Predicted satisfaction\", ge=1, le=10)\n",
    "\n",
    "\n",
    "# General inquiry agent\n",
    "general_agent = Agent(\n",
    "    \"openai:gpt-4o\",\n",
    "    deps_type=CustomerServiceDeps,\n",
    "    output_type=ServiceOutput,\n",
    "    system_prompt=\"You are a helpful customer service agent for general inquiries.\",\n",
    "    instrument=True,\n",
    ")\n",
    "\n",
    "# Technical support agent\n",
    "technical_agent = Agent(\n",
    "    \"openai:gpt-4o\",\n",
    "    deps_type=CustomerServiceDeps,\n",
    "    output_type=ServiceOutput,\n",
    "    system_prompt=\"You are a technical support specialist for banking applications.\",\n",
    "    instrument=True,\n",
    ")\n",
    "\n",
    "\n",
    "@ag.instrument(spankind=\"workflow\")\n",
    "def route_customer_query(customer_id: int, query: str, query_type: str = \"general\"):\n",
    "    \"\"\"Route customer queries to appropriate specialized agents.\"\"\"\n",
    "    deps = CustomerServiceDeps(customer_id=customer_id, db=DatabaseConn())\n",
    "\n",
    "    if query_type == \"technical\":\n",
    "        result = technical_agent.run_sync(query, deps=deps)\n",
    "    else:\n",
    "        result = general_agent.run_sync(query, deps=deps)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Multi-Agent System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test general inquiry\n",
    "general_result = route_customer_query(123, \"What are your bank hours?\", \"general\")\n",
    "print(\"General Inquiry Result:\")\n",
    "print(f\"Response: {general_result.output.response}\")\n",
    "print(f\"Escalate: {general_result.output.escalate}\")\n",
    "print(f\"Satisfaction Score: {general_result.output.satisfaction_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test technical inquiry\n",
    "technical_result = route_customer_query(123, \"My mobile app is crashing\", \"technical\")\n",
    "print(\"Technical Inquiry Result:\")\n",
    "print(f\"Response: {technical_result.output.response}\")\n",
    "print(f\"Escalate: {technical_result.output.escalate}\")\n",
    "print(f\"Satisfaction Score: {technical_result.output.satisfaction_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fraud Detection Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FraudDeps:\n",
    "    def __init__(self, transaction_id: str, customer_id: int):\n",
    "        self.transaction_id = transaction_id\n",
    "        self.customer_id = customer_id\n",
    "\n",
    "\n",
    "class FraudOutput(BaseModel):\n",
    "    is_fraudulent: bool = Field(description=\"Whether transaction is fraudulent\")\n",
    "    confidence: float = Field(description=\"Confidence score\", ge=0.0, le=1.0)\n",
    "    reason: str = Field(description=\"Explanation for the decision\")\n",
    "    action: str = Field(description=\"Recommended action\")\n",
    "\n",
    "\n",
    "fraud_agent = Agent(\n",
    "    \"openai:gpt-4o\",\n",
    "    deps_type=FraudDeps,\n",
    "    output_type=FraudOutput,\n",
    "    system_prompt=(\n",
    "        \"You are a fraud detection specialist. Analyze transactions \"\n",
    "        \"and determine if they are potentially fraudulent.\"\n",
    "    ),\n",
    "    instrument=True,\n",
    ")\n",
    "\n",
    "\n",
    "@fraud_agent.tool\n",
    "async def get_transaction_history(ctx: RunContext[FraudDeps]) -> str:\n",
    "    \"\"\"Get recent transaction history for the customer.\"\"\"\n",
    "    # Mock transaction history\n",
    "    return f\"Recent transactions for customer {ctx.deps.customer_id}: $50.00, $25.00, $100.00\"\n",
    "\n",
    "\n",
    "@fraud_agent.tool\n",
    "async def get_customer_profile(ctx: RunContext[FraudDeps]) -> str:\n",
    "    \"\"\"Get customer profile and spending patterns.\"\"\"\n",
    "    # Mock customer profile\n",
    "    return f\"Customer {ctx.deps.customer_id}: Average monthly spending $500, Location: New York\"\n",
    "\n",
    "\n",
    "@ag.instrument(spankind=\"agent\")\n",
    "def analyze_transaction(\n",
    "    transaction_id: str, customer_id: int, amount: float, location: str\n",
    "):\n",
    "    \"\"\"Analyze a transaction for potential fraud.\"\"\"\n",
    "    deps = FraudDeps(transaction_id=transaction_id, customer_id=customer_id)\n",
    "    query = f\"Analyze transaction {transaction_id}: ${amount} in {location}\"\n",
    "\n",
    "    result = fraud_agent.run_sync(query, deps=deps)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Fraud Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test fraud detection\n",
    "fraud_result = analyze_transaction(\"txn_12345\", 123, 5000.0, \"Nigeria\")\n",
    "print(\"Fraud Detection Result:\")\n",
    "print(f\"Is Fraudulent: {fraud_result.output.is_fraudulent}\")\n",
    "print(f\"Confidence: {fraud_result.output.confidence}\")\n",
    "print(f\"Reason: {fraud_result.output.reason}\")\n",
    "print(f\"Action: {fraud_result.output.action}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Investment Advisory Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvestmentDeps:\n",
    "    def __init__(self, customer_id: int, portfolio_value: float):\n",
    "        self.customer_id = customer_id\n",
    "        self.portfolio_value = portfolio_value\n",
    "\n",
    "\n",
    "class InvestmentOutput(BaseModel):\n",
    "    recommendation: str = Field(description=\"Investment recommendation\")\n",
    "    risk_level: str = Field(description=\"Risk level assessment\")\n",
    "    expected_return: float = Field(description=\"Expected annual return percentage\")\n",
    "    timeframe: str = Field(description=\"Recommended investment timeframe\")\n",
    "\n",
    "\n",
    "investment_agent = Agent(\n",
    "    \"openai:gpt-4o\",\n",
    "    deps_type=InvestmentDeps,\n",
    "    output_type=InvestmentOutput,\n",
    "    system_prompt=(\n",
    "        \"You are an investment advisor. Provide personalized investment \"\n",
    "        \"recommendations based on customer profile and market conditions.\"\n",
    "    ),\n",
    "    instrument=True,\n",
    ")\n",
    "\n",
    "\n",
    "@investment_agent.tool\n",
    "async def get_market_data(ctx: RunContext[InvestmentDeps]) -> str:\n",
    "    \"\"\"Get current market conditions and trends.\"\"\"\n",
    "    return \"Current market: S&P 500 up 2%, bonds stable, commodities mixed\"\n",
    "\n",
    "\n",
    "@investment_agent.tool\n",
    "async def get_customer_risk_profile(ctx: RunContext[InvestmentDeps]) -> str:\n",
    "    \"\"\"Get customer's risk tolerance and investment goals.\"\"\"\n",
    "    return f\"Customer {ctx.deps.customer_id}: Moderate risk tolerance, retirement savings goal\"\n",
    "\n",
    "\n",
    "@ag.instrument(spankind=\"workflow\")\n",
    "def get_investment_advice(customer_id: int, portfolio_value: float, query: str):\n",
    "    \"\"\"Provide investment advice based on customer profile and query.\"\"\"\n",
    "    deps = InvestmentDeps(customer_id=customer_id, portfolio_value=portfolio_value)\n",
    "    result = investment_agent.run_sync(query, deps=deps)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Investment Advisory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test investment advice\n",
    "investment_result = get_investment_advice(\n",
    "    123, 50000.0, \"I want to diversify my portfolio for retirement\"\n",
    ")\n",
    "print(\"Investment Advisory Result:\")\n",
    "print(f\"Recommendation: {investment_result.output.recommendation}\")\n",
    "print(f\"Risk Level: {investment_result.output.risk_level}\")\n",
    "print(f\"Expected Return: {investment_result.output.expected_return}%\")\n",
    "print(f\"Timeframe: {investment_result.output.timeframe}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "For more detailed information about Agenta's observability features and advanced configuration options, visit the [Agenta Observability SDK Documentation](/observability/observability-sdk)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
