{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analytics API - Tutorial\n",
    "\n",
    "This tutorial demonstrates how to use the Agenta Analytics API to analyze LLM performance metrics. You'll learn how to:\n",
    "\n",
    "- Retrieve aggregated metrics over time\n",
    "- Analyze costs, latency, and token usage\n",
    "- Filter analytics by status and other attributes\n",
    "- Track error trends and failure rates\n",
    "- Compare performance across different time periods\n",
    "\n",
    "## What You'll Build\n",
    "\n",
    "We'll create analytics queries that:\n",
    "1. Track daily LLM costs and spending trends\n",
    "2. Monitor error rates and identify peak error times\n",
    "3. Analyze token usage patterns\n",
    "4. Compare performance metrics over time\n",
    "5. Generate cost reports and visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Before using the API, you need your Agenta API key. You can create API keys from the Settings page in your Agenta workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from getpass import getpass\n",
    "\n",
    "# Configuration\n",
    "AGENTA_HOST = os.getenv(\"AGENTA_HOST\", \"https://cloud.agenta.ai\")\n",
    "api_key = os.getenv(\"AGENTA_API_KEY\")\n",
    "if not api_key:\n",
    "    api_key = getpass(\"Enter your Agenta API key: \")\n",
    "    os.environ[\"AGENTA_API_KEY\"] = api_key\n",
    "\n",
    "# Setup base configuration\n",
    "BASE_URL = f\"{AGENTA_HOST}/api/preview/tracing/spans/analytics\"\n",
    "HEADERS = {\n",
    "    \"Authorization\": f\"ApiKey {api_key}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "print(\"✅ Setup complete!\")\n",
    "print(f\"API endpoint: {BASE_URL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Get Recent Metrics\n",
    "\n",
    "Let's start by retrieving metrics for the last 7 days with daily buckets. Each bucket contains aggregated metrics for all traces within that day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get analytics for last 7 days with daily buckets\n",
    "newest = datetime.now(timezone.utc)\n",
    "oldest = newest - timedelta(days=7)\n",
    "\n",
    "payload = {\n",
    "    \"focus\": \"trace\",\n",
    "    \"interval\": 1440,  # 1440 minutes = daily buckets\n",
    "    \"windowing\": {\n",
    "        \"oldest\": oldest.isoformat(),\n",
    "        \"newest\": newest.isoformat()\n",
    "    }\n",
    "}\n",
    "\n",
    "response = requests.post(BASE_URL, headers=HEADERS, json=payload)\n",
    "data = response.json()\n",
    "\n",
    "print(f\"📊 Found {data['count']} daily buckets\\n\")\n",
    "\n",
    "# Show all days with activity\n",
    "for bucket in data['buckets']:\n",
    "    if bucket['total']['count'] > 0:\n",
    "        date = bucket['timestamp'][:10]\n",
    "        print(f\"Date: {date}\")\n",
    "        print(f\"  Traces: {bucket['total']['count']}\")\n",
    "        print(f\"  Cost: ${bucket['total']['costs']:.4f}\")\n",
    "        print(f\"  Tokens: {bucket['total']['tokens']:,.0f}\")\n",
    "        print(f\"  Errors: {bucket['errors']['count']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Track Daily Costs\n",
    "\n",
    "Calculate total costs and generate summary statistics over a time period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get daily metrics for last 30 days\n",
    "newest = datetime.now(timezone.utc)\n",
    "oldest = newest - timedelta(days=30)\n",
    "\n",
    "payload = {\n",
    "    \"focus\": \"trace\",\n",
    "    \"interval\": 1440,  # Daily buckets\n",
    "    \"windowing\": {\n",
    "        \"oldest\": oldest.isoformat(),\n",
    "        \"newest\": newest.isoformat()\n",
    "    }\n",
    "}\n",
    "\n",
    "response = requests.post(BASE_URL, headers=HEADERS, json=payload)\n",
    "data = response.json()\n",
    "\n",
    "# Calculate totals\n",
    "total_traces = sum(b['total']['count'] for b in data['buckets'])\n",
    "total_cost = sum(b['total']['costs'] for b in data['buckets'])\n",
    "total_tokens = sum(b['total']['tokens'] for b in data['buckets'])\n",
    "total_errors = sum(b['errors']['count'] for b in data['buckets'])\n",
    "\n",
    "print(\"💰 Cost Summary (Last 30 Days)\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Total Cost: ${total_cost:.2f}\")\n",
    "print(f\"Total Requests: {total_traces:,}\")\n",
    "if total_traces > 0:\n",
    "    print(f\"Average Cost per Request: ${total_cost/total_traces:.6f}\")\n",
    "    print(f\"Total Tokens: {total_tokens:,.0f}\")\n",
    "    print(f\"Average Tokens per Request: {total_tokens/total_traces:.1f}\")\n",
    "    print(f\"Error Rate: {(total_errors/total_traces)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Analyze Error Trends\n",
    "\n",
    "Monitor error rates over time to identify patterns and peak error times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get hourly metrics for last 7 days\n",
    "newest = datetime.now(timezone.utc)\n",
    "oldest = newest - timedelta(days=7)\n",
    "\n",
    "payload = {\n",
    "    \"focus\": \"trace\",\n",
    "    \"interval\": 60,  # Hourly buckets\n",
    "    \"windowing\": {\n",
    "        \"oldest\": oldest.isoformat(),\n",
    "        \"newest\": newest.isoformat()\n",
    "    }\n",
    "}\n",
    "\n",
    "response = requests.post(BASE_URL, headers=HEADERS, json=payload)\n",
    "data = response.json()\n",
    "\n",
    "print(\"🚨 Error Analysis\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Find hours with high error rates\n",
    "high_error_periods = []\n",
    "for bucket in data['buckets']:\n",
    "    if bucket['total']['count'] > 0:\n",
    "        error_rate = (bucket['errors']['count'] / bucket['total']['count']) * 100\n",
    "        if error_rate > 5:  # Flag periods with > 5% errors\n",
    "            high_error_periods.append({\n",
    "                'time': bucket['timestamp'],\n",
    "                'error_rate': error_rate,\n",
    "                'total': bucket['total']['count'],\n",
    "                'errors': bucket['errors']['count']\n",
    "            })\n",
    "\n",
    "if high_error_periods:\n",
    "    print(f\"\\nFound {len(high_error_periods)} periods with high error rates (>5%):\\n\")\n",
    "    for period in high_error_periods[:10]:  # Show top 10\n",
    "        print(f\"  {period['time']}\")\n",
    "        print(f\"    Error Rate: {period['error_rate']:.1f}%\")\n",
    "        print(f\"    Total: {period['total']}, Errors: {period['errors']}\\n\")\n",
    "else:\n",
    "    print(\"✅ No high error rates detected in the last 7 days\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Filter by Status Code\n",
    "\n",
    "Analyze only successful traces by filtering on status code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get successful traces only\n",
    "newest = datetime.now(timezone.utc)\n",
    "oldest = newest - timedelta(days=7)\n",
    "\n",
    "payload = {\n",
    "    \"focus\": \"trace\",\n",
    "    \"interval\": 1440,  # Daily buckets\n",
    "    \"windowing\": {\n",
    "        \"oldest\": oldest.isoformat(),\n",
    "        \"newest\": newest.isoformat()\n",
    "    },\n",
    "    \"filter\": {\n",
    "        \"conditions\": [\n",
    "            {\n",
    "                \"field\": \"status.code\",\n",
    "                \"operator\": \"eq\",\n",
    "                \"value\": \"STATUS_CODE_OK\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "response = requests.post(BASE_URL, headers=HEADERS, json=payload)\n",
    "data = response.json()\n",
    "\n",
    "# Calculate success metrics\n",
    "total_count = sum(b['total']['count'] for b in data['buckets'])\n",
    "total_cost = sum(b['total']['costs'] for b in data['buckets'])\n",
    "total_duration = sum(b['total']['duration'] for b in data['buckets'])\n",
    "\n",
    "print(\"✅ Successful Traces (Last 7 Days)\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Count: {total_count:,}\")\n",
    "print(f\"Total Cost: ${total_cost:.4f}\")\n",
    "if total_count > 0:\n",
    "    print(f\"Avg Duration: {total_duration/total_count:.0f}ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Track Token Usage\n",
    "\n",
    "Monitor token consumption patterns over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get daily token usage for last 7 days\n",
    "newest = datetime.now(timezone.utc)\n",
    "oldest = newest - timedelta(days=7)\n",
    "\n",
    "payload = {\n",
    "    \"focus\": \"trace\",\n",
    "    \"interval\": 1440,  # Daily buckets\n",
    "    \"windowing\": {\n",
    "        \"oldest\": oldest.isoformat(),\n",
    "        \"newest\": newest.isoformat()\n",
    "    }\n",
    "}\n",
    "\n",
    "response = requests.post(BASE_URL, headers=HEADERS, json=payload)\n",
    "data = response.json()\n",
    "\n",
    "print(\"🎯 Token Usage Analysis\")\n",
    "print(\"=\" * 50)\n",
    "print(\"\\nDaily Token Usage:\\n\")\n",
    "\n",
    "for bucket in data['buckets']:\n",
    "    if bucket['total']['count'] > 0:\n",
    "        date = bucket['timestamp'][:10]\n",
    "        avg_tokens = bucket['total']['tokens'] / bucket['total']['count']\n",
    "        print(f\"  {date}: {bucket['total']['tokens']:>8,.0f} total ({avg_tokens:>6.0f} avg)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Analyze Performance\n",
    "\n",
    "Track latency trends over time to identify performance changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get hourly performance for last 24 hours\n",
    "newest = datetime.now(timezone.utc)\n",
    "oldest = newest - timedelta(days=1)\n",
    "\n",
    "payload = {\n",
    "    \"focus\": \"trace\",\n",
    "    \"interval\": 60,  # Hourly buckets\n",
    "    \"windowing\": {\n",
    "        \"oldest\": oldest.isoformat(),\n",
    "        \"newest\": newest.isoformat()\n",
    "    }\n",
    "}\n",
    "\n",
    "response = requests.post(BASE_URL, headers=HEADERS, json=payload)\n",
    "data = response.json()\n",
    "\n",
    "print(\"⚡ Performance Analysis (Last 24 Hours)\")\n",
    "print(\"=\" * 50)\n",
    "print(\"\\nHourly Average Latency:\\n\")\n",
    "\n",
    "latencies = []\n",
    "for bucket in data['buckets']:\n",
    "    if bucket['total']['count'] > 0:\n",
    "        avg_duration = bucket['total']['duration'] / bucket['total']['count']\n",
    "        latencies.append(avg_duration)\n",
    "        hour = bucket['timestamp'][11:16]  # Extract HH:MM\n",
    "        print(f\"  {hour}: {avg_duration:7.0f}ms\")\n",
    "\n",
    "if latencies:\n",
    "    print(f\"\\n📈 Statistics:\")\n",
    "    print(f\"  Min: {min(latencies):.0f}ms\")\n",
    "    print(f\"  Max: {max(latencies):.0f}ms\")\n",
    "    print(f\"  Avg: {sum(latencies)/len(latencies):.0f}ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Generate Monthly Cost Report\n",
    "\n",
    "Create a comprehensive monthly report with cost breakdown and usage statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get monthly metrics\n",
    "newest = datetime.now(timezone.utc)\n",
    "oldest = newest - timedelta(days=30)\n",
    "\n",
    "payload = {\n",
    "    \"focus\": \"trace\",\n",
    "    \"interval\": 1440,  # Daily buckets\n",
    "    \"windowing\": {\n",
    "        \"oldest\": oldest.isoformat(),\n",
    "        \"newest\": newest.isoformat()\n",
    "    }\n",
    "}\n",
    "\n",
    "response = requests.post(BASE_URL, headers=HEADERS, json=payload)\n",
    "data = response.json()\n",
    "\n",
    "# Calculate totals\n",
    "total_traces = sum(b['total']['count'] for b in data['buckets'])\n",
    "total_cost = sum(b['total']['costs'] for b in data['buckets'])\n",
    "total_tokens = sum(b['total']['tokens'] for b in data['buckets'])\n",
    "total_duration = sum(b['total']['duration'] for b in data['buckets'])\n",
    "total_errors = sum(b['errors']['count'] for b in data['buckets'])\n",
    "\n",
    "print(\"📊 MONTHLY COST REPORT\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Period: {oldest.strftime('%Y-%m-%d')} to {newest.strftime('%Y-%m-%d')}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\n💰 Cost Summary:\")\n",
    "print(f\"  Total Cost: ${total_cost:.2f}\")\n",
    "if total_traces > 0:\n",
    "    print(f\"  Average Cost per Request: ${total_cost/total_traces:.6f}\")\n",
    "daily_cost = total_cost / 30\n",
    "print(f\"  Average Daily Cost: ${daily_cost:.2f}\")\n",
    "print(f\"  Projected Monthly Cost: ${daily_cost * 30:.2f}\")\n",
    "\n",
    "print(\"\\n📊 Usage Statistics:\")\n",
    "print(f\"  Total Requests: {total_traces:,}\")\n",
    "successful = total_traces - total_errors\n",
    "print(f\"  Successful: {successful:,}\")\n",
    "print(f\"  Failed: {total_errors:,}\")\n",
    "if total_traces > 0:\n",
    "    print(f\"  Failure Rate: {(total_errors/total_traces)*100:.2f}%\")\n",
    "    print(f\"  Average Daily Requests: {total_traces/30:.0f}\")\n",
    "\n",
    "print(\"\\n🎯 Performance Metrics:\")\n",
    "if total_traces > 0:\n",
    "    print(f\"  Average Latency: {total_duration/total_traces:.0f}ms\")\n",
    "print(f\"  Total Tokens: {total_tokens:,.0f}\")\n",
    "if total_traces > 0:\n",
    "    print(f\"  Average Tokens per Request: {total_tokens/total_traces:.1f}\")\n",
    "    print(f\"  Average Daily Tokens: {total_tokens/30:,.0f}\")\n",
    "\n",
    "# Cost per 1K tokens\n",
    "if total_tokens > 0:\n",
    "    cost_per_1k = (total_cost / total_tokens) * 1000\n",
    "    print(f\"  Cost per 1K Tokens: ${cost_per_1k:.4f}\")\n",
    "\n",
    "# Find most expensive days\n",
    "print(\"\\n📅 Top 5 Most Expensive Days:\")\n",
    "days_with_data = [(b['timestamp'][:10], b['total']['costs'], b['total']['count']) \n",
    "                  for b in data['buckets'] if b['total']['count'] > 0]\n",
    "sorted_days = sorted(days_with_data, key=lambda x: x[1], reverse=True)\n",
    "for i, (date, cost, count) in enumerate(sorted_days[:5], 1):\n",
    "    print(f\"  {i}. {date}: ${cost:.4f} ({count} requests)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: Compare Week-over-Week Performance\n",
    "\n",
    "Analyze how metrics change from one week to the next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to get weekly metrics\n",
    "def get_weekly_metrics(weeks_ago=0):\n",
    "    newest = datetime.now(timezone.utc) - timedelta(weeks=weeks_ago)\n",
    "    oldest = newest - timedelta(days=7)\n",
    "    \n",
    "    payload = {\n",
    "        \"focus\": \"trace\",\n",
    "        \"interval\": 10080,  # Weekly bucket\n",
    "        \"windowing\": {\n",
    "            \"oldest\": oldest.isoformat(),\n",
    "            \"newest\": newest.isoformat()\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    response = requests.post(BASE_URL, headers=HEADERS, json=payload)\n",
    "    data = response.json()\n",
    "    \n",
    "    if data['buckets']:\n",
    "        bucket = data['buckets'][0]\n",
    "        return {\n",
    "            'count': bucket['total']['count'],\n",
    "            'costs': bucket['total']['costs'],\n",
    "            'duration': bucket['total']['duration'],\n",
    "            'tokens': bucket['total']['tokens'],\n",
    "            'errors': bucket['errors']['count']\n",
    "        }\n",
    "    return None\n",
    "\n",
    "this_week = get_weekly_metrics(0)\n",
    "last_week = get_weekly_metrics(1)\n",
    "\n",
    "def calc_change(current, previous):\n",
    "    if previous == 0:\n",
    "        return \"N/A\"\n",
    "    change = ((current - previous) / previous) * 100\n",
    "    symbol = \"📈\" if change > 0 else \"📉\" if change < 0 else \"➡️\"\n",
    "    return f\"{symbol} {change:+.1f}%\"\n",
    "\n",
    "print(\"📊 Week-over-Week Comparison\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if this_week and last_week:\n",
    "    print(\"\\n💰 Cost:\")\n",
    "    print(f\"  Last Week: ${last_week['costs']:.4f}\")\n",
    "    print(f\"  This Week: ${this_week['costs']:.4f}\")\n",
    "    print(f\"  Change: {calc_change(this_week['costs'], last_week['costs'])}\")\n",
    "\n",
    "    print(\"\\n📊 Volume:\")\n",
    "    print(f\"  Last Week: {last_week['count']:,} requests\")\n",
    "    print(f\"  This Week: {this_week['count']:,} requests\")\n",
    "    print(f\"  Change: {calc_change(this_week['count'], last_week['count'])}\")\n",
    "\n",
    "    print(\"\\n⚡ Performance:\")\n",
    "    last_avg = last_week['duration'] / last_week['count'] if last_week['count'] > 0 else 0\n",
    "    this_avg = this_week['duration'] / this_week['count'] if this_week['count'] > 0 else 0\n",
    "    print(f\"  Last Week: {last_avg:.0f}ms\")\n",
    "    print(f\"  This Week: {this_avg:.0f}ms\")\n",
    "    print(f\"  Change: {calc_change(this_avg, last_avg)}\")\n",
    "\n",
    "    print(\"\\n🚨 Error Rate:\")\n",
    "    last_err_rate = (last_week['errors'] / last_week['count'] * 100) if last_week['count'] > 0 else 0\n",
    "    this_err_rate = (this_week['errors'] / this_week['count'] * 100) if this_week['count'] > 0 else 0\n",
    "    print(f\"  Last Week: {last_err_rate:.2f}%\")\n",
    "    print(f\"  This Week: {this_err_rate:.2f}%\")\n",
    "    print(f\"  Change: {calc_change(this_err_rate, last_err_rate)}\")\n",
    "else:\n",
    "    print(\"\\n⚠️ Not enough data for comparison\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 9: Create Visualizations\n",
    "\n",
    "Visualize cost and usage trends using matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.dates as mdates\n",
    "    from datetime import datetime\n",
    "    \n",
    "    # Get daily metrics for last 30 days\n",
    "    newest = datetime.now(timezone.utc)\n",
    "    oldest = newest - timedelta(days=30)\n",
    "\n",
    "    payload = {\n",
    "        \"focus\": \"trace\",\n",
    "        \"interval\": 1440,  # Daily buckets\n",
    "        \"windowing\": {\n",
    "            \"oldest\": oldest.isoformat(),\n",
    "            \"newest\": newest.isoformat()\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = requests.post(BASE_URL, headers=HEADERS, json=payload)\n",
    "    data = response.json()\n",
    "\n",
    "    # Extract dates and metrics\n",
    "    dates = [datetime.fromisoformat(b['timestamp'].replace('Z', '+00:00')) \n",
    "             for b in data['buckets'] if b['total']['count'] > 0]\n",
    "    costs = [b['total']['costs'] for b in data['buckets'] if b['total']['count'] > 0]\n",
    "    counts = [b['total']['count'] for b in data['buckets'] if b['total']['count'] > 0]\n",
    "\n",
    "    # Create figure with two subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))\n",
    "\n",
    "    # Plot 1: Daily Cost\n",
    "    ax1.plot(dates, costs, marker='o', linewidth=2, markersize=4, color='#2563eb')\n",
    "    ax1.set_title('Daily LLM Costs (Last 30 Days)', fontsize=14, fontweight='bold')\n",
    "    ax1.set_ylabel('Cost ($)', fontsize=12)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.xaxis.set_major_formatter(mdates.DateFormatter('%m/%d'))\n",
    "    plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45)\n",
    "\n",
    "    # Plot 2: Daily Request Volume\n",
    "    ax2.bar(dates, counts, alpha=0.7, color='steelblue')\n",
    "    ax2.set_title('Daily Request Volume (Last 30 Days)', fontsize=14, fontweight='bold')\n",
    "    ax2.set_xlabel('Date', fontsize=12)\n",
    "    ax2.set_ylabel('Requests', fontsize=12)\n",
    "    ax2.grid(True, alpha=0.3, axis='y')\n",
    "    ax2.xaxis.set_major_formatter(mdates.DateFormatter('%m/%d'))\n",
    "    plt.setp(ax2.xaxis.get_majorticklabels(), rotation=45)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"✅ Visualizations created successfully!\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"⚠️ matplotlib not installed. Run: pip install matplotlib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 10: Export Data to DataFrame\n",
    "\n",
    "Convert analytics data to a pandas DataFrame for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import pandas as pd\n",
    "    \n",
    "    # Get daily metrics for last 30 days\n",
    "    newest = datetime.now(timezone.utc)\n",
    "    oldest = newest - timedelta(days=30)\n",
    "\n",
    "    payload = {\n",
    "        \"focus\": \"trace\",\n",
    "        \"interval\": 1440,  # Daily buckets\n",
    "        \"windowing\": {\n",
    "            \"oldest\": oldest.isoformat(),\n",
    "            \"newest\": newest.isoformat()\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = requests.post(BASE_URL, headers=HEADERS, json=payload)\n",
    "    data = response.json()\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    rows = []\n",
    "    for bucket in data['buckets']:\n",
    "        if bucket['total']['count'] > 0:  # Only include days with data\n",
    "            rows.append({\n",
    "                'timestamp': bucket['timestamp'],\n",
    "                'total_count': bucket['total']['count'],\n",
    "                'total_cost': bucket['total']['costs'],\n",
    "                'total_duration': bucket['total']['duration'],\n",
    "                'total_tokens': bucket['total']['tokens'],\n",
    "                'error_count': bucket['errors']['count'],\n",
    "                'error_duration': bucket['errors']['duration'],\n",
    "                'avg_duration': bucket['total']['duration'] / bucket['total']['count'],\n",
    "                'avg_cost': bucket['total']['costs'] / bucket['total']['count'],\n",
    "                'error_rate': (bucket['errors']['count'] / bucket['total']['count'] * 100)\n",
    "            })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "    print(\"📊 Analytics Data Summary\\n\")\n",
    "    print(df.describe())\n",
    "    \n",
    "    print(\"\\n📅 Recent Days:\")\n",
    "    print(df.tail(10).to_string())\n",
    "    \n",
    "    # Optional: Save to CSV\n",
    "    # df.to_csv('analytics_export.csv', index=False)\n",
    "    # print(\"\\n✅ Data exported to analytics_export.csv\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"⚠️ pandas not installed. Run: pip install pandas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, you learned how to:\n",
    "\n",
    "1. ✅ **Retrieve aggregated metrics** using the Analytics API\n",
    "2. ✅ **Track daily costs** and generate spending reports\n",
    "3. ✅ **Analyze error trends** to identify reliability issues\n",
    "4. ✅ **Filter by status code** to analyze successful vs failed traces\n",
    "5. ✅ **Track token usage** patterns over time\n",
    "6. ✅ **Monitor performance** and latency trends\n",
    "7. ✅ **Generate monthly reports** with comprehensive cost breakdowns\n",
    "8. ✅ **Compare week-over-week** metrics to identify trends\n",
    "9. ✅ **Visualize data** using matplotlib\n",
    "10. ✅ **Export to DataFrame** for further analysis\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Learn about [Query API](/observability/query-data/query-api) for detailed trace analysis\n",
    "- Explore [Using the UI](/observability/using-the-ui/filtering-traces) for visual analytics\n",
    "- Check out [Semantic Conventions](/observability/concepts/semantic-conventions) for available metrics\n",
    "- Read about [Cost Tracking](/observability/trace-with-python-sdk/track-costs) for automatic cost calculation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
