{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Query Data API - Tutorial\n",
        "\n",
        "This tutorial shows you how to use the Agenta Query Data API to retrieve and analyze your LLM traces. You'll learn how to:\n",
        "\n",
        "- Set up the API client with authentication\n",
        "- Query spans and traces with filters\n",
        "- Filter by attributes, time ranges, and status codes\n",
        "- Use advanced filters with logical operators\n",
        "- Analyze trace data to calculate costs and latencies\n",
        "\n",
        "## What You'll Build\n",
        "\n",
        "We'll create scripts that:\n",
        "1. Query recent traces from your applications\n",
        "2. Filter traces by type, status, and custom attributes\n",
        "3. Analyze cost and performance metrics\n",
        "4. Find problematic traces (errors, slow responses)\n",
        "5. Export trace data for further analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install -U requests pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Setup\n\nBefore using the API, you need your Agenta API key. You can create API keys from the Settings page in your Agenta workspace."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"AGENTA_HOST\"] = \"https://cloud.agenta.ai\"  # Default value, change for self-hosted\n",
        "os.environ[\"AGENTA_API_KEY\"] = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "from getpass import getpass\n",
        "from datetime import datetime, timedelta, timezone\n",
        "import json\n",
        "\n",
        "# Get API credentials\n",
        "AGENTA_HOST = os.getenv(\"AGENTA_HOST\", \"https://cloud.agenta.ai\")\n",
        "api_key = os.getenv(\"AGENTA_API_KEY\")\n",
        "if not api_key:\n",
        "    api_key = getpass(\"Enter your Agenta API key: \")\n",
        "    os.environ[\"AGENTA_API_KEY\"] = api_key\n",
        "\n",
        "# Setup base configuration\n",
        "BASE_URL = f\"{AGENTA_HOST}/api/preview/tracing/spans/query\"\n",
        "HEADERS = {\n",
        "    \"Authorization\": f\"ApiKey {api_key}\",\n",
        "    \"Content-Type\": \"application/json\"\n",
        "}\n",
        "\n",
        "print(f\"\u2713 Connected to {AGENTA_HOST}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 1: Query Recent Traces\n",
        "\n",
        "Let's start by querying traces from the last 7 days. We'll use the `focus=trace` parameter to get complete trace trees instead of individual spans."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Query traces from the last 7 days\n",
        "now = datetime.now(timezone.utc)\n",
        "week_ago = now - timedelta(days=7)\n",
        "\n",
        "query = {\n",
        "    \"focus\": \"trace\",\n",
        "    \"oldest\": week_ago.isoformat(),\n",
        "    \"newest\": now.isoformat(),\n",
        "    \"limit\": 5\n",
        "}\n",
        "\n",
        "response = requests.post(BASE_URL, headers=HEADERS, json=query)\n",
        "data = response.json()\n",
        "\n",
        "print(f\"Found {data['count']} traces\")\n",
        "print(f\"Trace IDs: {list(data.get('traces', {}).keys())}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 2: Query Spans with Filters\n",
        "\n",
        "Now let's query individual spans and filter by type. We'll look for LLM spans specifically."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Query LLM spans\n",
        "query = {\n",
        "    \"focus\": \"span\",\n",
        "    \"limit\": 10,\n",
        "    \"filter\": {\n",
        "        \"operator\": \"and\",\n",
        "        \"conditions\": [\n",
        "            {\n",
        "                \"field\": \"attributes\",\n",
        "                \"key\": \"ag.type.span\",\n",
        "                \"operator\": \"is\",\n",
        "                \"value\": \"llm\"\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "}\n",
        "\n",
        "response = requests.post(BASE_URL, headers=HEADERS, json=query)\n",
        "data = response.json()\n",
        "\n",
        "print(f\"Found {data['count']} LLM spans\")\n",
        "\n",
        "# Display first span details\n",
        "if data.get('spans'):\n",
        "    span = data['spans'][0]\n",
        "    print(f\"\\nFirst span:\")\n",
        "    print(f\"  Name: {span.get('span_name')}\")\n",
        "    print(f\"  Status: {span.get('status_code')}\")\n",
        "    print(f\"  Start: {span.get('start_time')}\")\n",
        "    print(f\"  End: {span.get('end_time')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 3: Filter by Status Code\n",
        "\n",
        "Let's find traces that encountered errors. This is useful for debugging and monitoring application health."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find error traces\n",
        "query = {\n",
        "    \"focus\": \"trace\",\n",
        "    \"limit\": 10,\n",
        "    \"filter\": {\n",
        "        \"operator\": \"and\",\n",
        "        \"conditions\": [\n",
        "            {\n",
        "                \"field\": \"status_code\",\n",
        "                \"operator\": \"is\",\n",
        "                \"value\": \"STATUS_CODE_ERROR\"\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "}\n",
        "\n",
        "response = requests.post(BASE_URL, headers=HEADERS, json=query)\n",
        "data = response.json()\n",
        "\n",
        "print(f\"Found {data['count']} traces with errors\")\n",
        "\n",
        "if data.get('traces'):\n",
        "    for trace_id in list(data['traces'].keys())[:3]:\n",
        "        print(f\"\\nError trace: {trace_id}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 4: Advanced Filtering with Multiple Conditions\n",
        "\n",
        "Let's use multiple filters to find specific traces. We'll look for successful LLM calls that took longer than 2 seconds."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find slow but successful LLM calls\n",
        "query = {\n",
        "    \"focus\": \"span\",\n",
        "    \"limit\": 10,\n",
        "    \"filter\": {\n",
        "        \"operator\": \"and\",\n",
        "        \"conditions\": [\n",
        "            {\n",
        "                \"field\": \"attributes\",\n",
        "                \"key\": \"ag.type.span\",\n",
        "                \"operator\": \"is\",\n",
        "                \"value\": \"llm\"\n",
        "            },\n",
        "            {\n",
        "                \"field\": \"status_code\",\n",
        "                \"operator\": \"is_not\",\n",
        "                \"value\": \"STATUS_CODE_ERROR\"\n",
        "            },\n",
        "            {\n",
        "                \"field\": \"attributes\",\n",
        "                \"key\": \"ag.metrics.unit.duration\",\n",
        "                \"operator\": \"gt\",\n",
        "                \"value\": 2000  # milliseconds\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "}\n",
        "\n",
        "response = requests.post(BASE_URL, headers=HEADERS, json=query)\n",
        "data = response.json()\n",
        "\n",
        "print(f\"Found {data['count']} slow LLM spans (>2s)\")\n",
        "\n",
        "if data.get('spans'):\n",
        "    for span in data['spans'][:3]:\n",
        "        duration = span.get('attributes', {}).get('ag', {}).get('metrics', {}).get('duration', {}).get('cumulative', 'N/A')\n",
        "        print(f\"  {span.get('span_name')}: {duration}ms\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 5: Nested Logical Operators\n",
        "\n",
        "Let's create a more complex query using nested logical operators. We'll find spans that are either errors OR slow responses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find problematic spans (errors OR slow)\n",
        "query = {\n",
        "    \"focus\": \"span\",\n",
        "    \"limit\": 10,\n",
        "    \"filter\": {\n",
        "        \"operator\": \"and\",\n",
        "        \"conditions\": [\n",
        "            {\n",
        "                \"field\": \"attributes\",\n",
        "                \"key\": \"ag.type.span\",\n",
        "                \"operator\": \"is\",\n",
        "                \"value\": \"llm\"\n",
        "            },\n",
        "            {\n",
        "                \"operator\": \"or\",\n",
        "                \"conditions\": [\n",
        "                    {\n",
        "                        \"field\": \"status_code\",\n",
        "                        \"value\": \"STATUS_CODE_ERROR\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"field\": \"attributes\",\n",
        "                        \"key\": \"ag.metrics.unit.duration\",\n",
        "                        \"operator\": \"gt\",\n",
        "                        \"value\": 5000\n",
        "                    }\n",
        "                ]\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "}\n",
        "\n",
        "response = requests.post(BASE_URL, headers=HEADERS, json=query)\n",
        "data = response.json()\n",
        "\n",
        "print(f\"Found {data['count']} problematic spans\")\n",
        "\n",
        "if data.get('spans'):\n",
        "    for span in data['spans'][:5]:\n",
        "        status = span.get('status_code')\n",
        "        duration = span.get('attributes', {}).get('ag', {}).get('metrics', {}).get('duration', {}).get('cumulative', 'N/A')\n",
        "        print(f\"  {span.get('span_name')}: Status={status}, Duration={duration}ms\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 6: Analyze Cost and Token Usage\n",
        "\n",
        "Let's query LLM spans and analyze their costs and token usage. This helps you understand your LLM spending."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Query LLM spans with cost tracking\n",
        "query = {\n",
        "    \"focus\": \"span\",\n",
        "    \"limit\": 50,\n",
        "    \"filter\": {\n",
        "        \"operator\": \"and\",\n",
        "        \"conditions\": [\n",
        "            {\n",
        "                \"field\": \"attributes\",\n",
        "                \"key\": \"ag.type.span\",\n",
        "                \"operator\": \"is\",\n",
        "                \"value\": \"llm\"\n",
        "            },\n",
        "            {\n",
        "                \"field\": \"attributes\",\n",
        "                \"key\": \"ag.metrics.unit.cost\",\n",
        "                \"operator\": \"exists\"\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "}\n",
        "\n",
        "response = requests.post(BASE_URL, headers=HEADERS, json=query)\n",
        "data = response.json()\n",
        "\n",
        "print(f\"Analyzing {data['count']} LLM spans with cost data\\n\")\n",
        "\n",
        "if data.get('spans'):\n",
        "    total_cost = 0\n",
        "    total_tokens = 0\n",
        "    total_duration = 0\n",
        "    \n",
        "    for span in data['spans']:\n",
        "        metrics = span.get('attributes', {}).get('ag', {}).get('metrics', {})\n",
        "        \n",
        "        # Extract cost\n",
        "        cost = metrics.get('costs', {}).get('cumulative', {}).get('total', 0)\n",
        "        total_cost += cost\n",
        "        \n",
        "        # Extract tokens\n",
        "        tokens = metrics.get('tokens', {}).get('cumulative', {}).get('total', 0)\n",
        "        total_tokens += tokens\n",
        "        \n",
        "        # Extract duration\n",
        "        duration = metrics.get('duration', {}).get('cumulative', 0)\n",
        "        total_duration += duration\n",
        "    \n",
        "    print(f\"Summary:\")\n",
        "    print(f\"  Total Cost: ${total_cost:.4f}\")\n",
        "    print(f\"  Total Tokens: {total_tokens:,}\")\n",
        "    print(f\"  Average Cost per Span: ${(total_cost/len(data['spans'])):.4f}\")\n",
        "    print(f\"  Average Tokens per Span: {int(total_tokens/len(data['spans']))}\")\n",
        "    print(f\"  Average Duration: {int(total_duration/len(data['spans']))}ms\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 7: Filter by Span Name Pattern\n",
        "\n",
        "Let's use string matching operators to find specific types of operations. We'll search for OpenAI-related spans."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find OpenAI spans using pattern matching\n",
        "query = {\n",
        "    \"focus\": \"span\",\n",
        "    \"limit\": 10,\n",
        "    \"filter\": {\n",
        "        \"operator\": \"and\",\n",
        "        \"conditions\": [\n",
        "            {\n",
        "                \"field\": \"span_name\",\n",
        "                \"operator\": \"contains\",\n",
        "                \"value\": \"openai\"\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "}\n",
        "\n",
        "response = requests.post(BASE_URL, headers=HEADERS, json=query)\n",
        "data = response.json()\n",
        "\n",
        "print(f\"Found {data['count']} OpenAI spans\")\n",
        "\n",
        "if data.get('spans'):\n",
        "    span_names = set(span.get('span_name') for span in data['spans'])\n",
        "    print(f\"\\nUnique span names:\")\n",
        "    for name in span_names:\n",
        "        print(f\"  - {name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 8: Export Trace Data to DataFrame\n",
        "\n",
        "Let's export our trace data to a pandas DataFrame for further analysis and visualization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Query recent spans\n",
        "query = {\n",
        "    \"focus\": \"span\",\n",
        "    \"limit\": 100,\n",
        "    \"filter\": {\n",
        "        \"operator\": \"and\",\n",
        "        \"conditions\": [\n",
        "            {\n",
        "                \"field\": \"attributes\",\n",
        "                \"key\": \"ag.type.span\",\n",
        "                \"operator\": \"is\",\n",
        "                \"value\": \"llm\"\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "}\n",
        "\n",
        "response = requests.post(BASE_URL, headers=HEADERS, json=query)\n",
        "data = response.json()\n",
        "\n",
        "# Convert to DataFrame\n",
        "records = []\n",
        "for span in data.get('spans', []):\n",
        "    metrics = span.get('attributes', {}).get('ag', {}).get('metrics', {})\n",
        "    \n",
        "    record = {\n",
        "        'trace_id': span.get('trace_id'),\n",
        "        'span_id': span.get('span_id'),\n",
        "        'span_name': span.get('span_name'),\n",
        "        'status': span.get('status_code'),\n",
        "        'start_time': span.get('start_time'),\n",
        "        'end_time': span.get('end_time'),\n",
        "        'duration_ms': metrics.get('duration', {}).get('cumulative', 0),\n",
        "        'cost': metrics.get('costs', {}).get('cumulative', {}).get('total', 0),\n",
        "        'total_tokens': metrics.get('tokens', {}).get('cumulative', {}).get('total', 0),\n",
        "        'prompt_tokens': metrics.get('tokens', {}).get('cumulative', {}).get('prompt', 0),\n",
        "        'completion_tokens': metrics.get('tokens', {}).get('cumulative', {}).get('completion', 0),\n",
        "    }\n",
        "    records.append(record)\n",
        "\n",
        "df = pd.DataFrame(records)\n",
        "\n",
        "print(f\"Created DataFrame with {len(df)} rows\\n\")\n",
        "print(\"First 5 rows:\")\n",
        "print(df.head())\n",
        "\n",
        "print(\"\\nBasic statistics:\")\n",
        "print(df[['duration_ms', 'cost', 'total_tokens']].describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 9: Time-Based Analysis\n",
        "\n",
        "Let's analyze how your costs and latencies change over time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert timestamps to datetime\n",
        "df['start_time'] = pd.to_datetime(df['start_time'])\n",
        "df['end_time'] = pd.to_datetime(df['end_time'])\n",
        "\n",
        "# Group by hour\n",
        "df['hour'] = df['start_time'].dt.floor('H')\n",
        "hourly_stats = df.groupby('hour').agg({\n",
        "    'span_id': 'count',\n",
        "    'duration_ms': 'mean',\n",
        "    'cost': 'sum',\n",
        "    'total_tokens': 'sum'\n",
        "}).rename(columns={'span_id': 'num_calls'})\n",
        "\n",
        "print(\"Hourly statistics:\")\n",
        "print(hourly_stats)\n",
        "\n",
        "print(f\"\\nPeak usage hour: {hourly_stats['num_calls'].idxmax()}\")\n",
        "print(f\"Highest cost hour: {hourly_stats['cost'].idxmax()} (${hourly_stats['cost'].max():.4f})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 10: Filter by Time Range\n",
        "\n",
        "Let's query traces from a specific time window. This is useful for analyzing specific incidents or time periods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Query last 24 hours\n",
        "now = datetime.now(timezone.utc)\n",
        "yesterday = now - timedelta(days=1)\n",
        "\n",
        "query = {\n",
        "    \"focus\": \"span\",\n",
        "    \"oldest\": yesterday.isoformat(),\n",
        "    \"newest\": now.isoformat(),\n",
        "    \"limit\": 100,\n",
        "    \"filter\": {\n",
        "        \"operator\": \"and\",\n",
        "        \"conditions\": [\n",
        "            {\n",
        "                \"field\": \"attributes\",\n",
        "                \"key\": \"ag.type.span\",\n",
        "                \"operator\": \"is\",\n",
        "                \"value\": \"llm\"\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "}\n",
        "\n",
        "response = requests.post(BASE_URL, headers=HEADERS, json=query)\n",
        "data = response.json()\n",
        "\n",
        "print(f\"Last 24 hours: {data['count']} LLM spans\")\n",
        "\n",
        "if data.get('spans'):\n",
        "    # Calculate totals\n",
        "    total_cost = sum(\n",
        "        span.get('attributes', {}).get('ag', {}).get('metrics', {}).get('costs', {}).get('cumulative', {}).get('total', 0)\n",
        "        for span in data['spans']\n",
        "    )\n",
        "    \n",
        "    error_count = sum(\n",
        "        1 for span in data['spans']\n",
        "        if span.get('status_code') == 'STATUS_CODE_ERROR'\n",
        "    )\n",
        "    \n",
        "    print(f\"\\nSummary for last 24 hours:\")\n",
        "    print(f\"  Total Cost: ${total_cost:.4f}\")\n",
        "    print(f\"  Error Rate: {(error_count/len(data['spans'])*100):.2f}%\")\n",
        "    print(f\"  Success Rate: {((len(data['spans'])-error_count)/len(data['spans'])*100):.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "In this tutorial, you learned how to:\n",
        "\n",
        "1. \u2713 Set up the Agenta Query Data API client\n",
        "2. \u2713 Query traces and spans with filters\n",
        "3. \u2713 Filter by attributes, status codes, and time ranges\n",
        "4. \u2713 Use advanced filters with logical operators\n",
        "5. \u2713 Analyze cost and performance metrics\n",
        "6. \u2713 Export trace data to pandas DataFrames\n",
        "7. \u2713 Perform time-based analysis\n",
        "\n",
        "## Next Steps\n",
        "\n",
        "- Learn about the [Analytics Data API](/observability/query-data/analytics-data) for aggregated metrics\n",
        "- Explore [filtering in the UI](/observability/using-the-ui/filtering-traces) for visual query building\n",
        "- Check out [trace annotations](/observability/trace-with-python-sdk/annotate-traces) for adding feedback data\n",
        "- Read the complete [API reference](/reference/api) for all available endpoints"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}